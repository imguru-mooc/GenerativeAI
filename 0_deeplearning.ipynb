{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcvUYqZm11Tz"
      },
      "outputs": [],
      "source": [
        "import numpy as np   # numeriacal computing\n",
        "import matplotlib.pyplot as plt  # plotting core\n",
        "\n",
        "x = np.array([1,2,3])\n",
        "y = np.array([1,2,3])\n",
        "print(x.ndim)\n",
        "print(x.shape)\n",
        "print(x.shape[0])\n",
        "print(len(x))\n",
        "\n",
        "plt.plot(x,y, 'r-' )\n",
        "plt.plot(x,y, 'bd' )\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNfcbyln11T2"
      },
      "outputs": [],
      "source": [
        "import numpy as np   # numeriacal computing\n",
        "import matplotlib.pyplot as plt  # plotting core\n",
        "\n",
        "x = np.array([1,2,3])\n",
        "y = np.array([1,2,3])\n",
        "\n",
        "w = 0\n",
        "b = 0\n",
        "\n",
        "y_hat = np.zeros(3)\n",
        "# print(y_hat)\n",
        "# print(len(x))\n",
        "# print(x.shape[0])\n",
        "# list(range(3))\n",
        "# for i in range(3):\n",
        "#     print(i)\n",
        "\n",
        "for i in range(len(x)):\n",
        "    y_hat[i] = w*x[i] + b;\n",
        "print(y_hat)\n",
        "\n",
        "plt.plot(x,y, 'o' )\n",
        "plt.plot(x,y, 'r-' )\n",
        "\n",
        "plt.plot(x,y_hat, 'o' )\n",
        "plt.plot(x,y_hat, 'b-' )\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te7X0p4L11T2"
      },
      "outputs": [],
      "source": [
        "import numpy as np   # numeriacal computing\n",
        "import matplotlib.pyplot as plt  # plotting core\n",
        "\n",
        "w = np.linspace(-1,3,100)\n",
        "# print(w)\n",
        "# print(len(w))\n",
        "b = 0\n",
        "x = 2\n",
        "y = 2\n",
        "\n",
        "j = np.zeros(100)\n",
        "\n",
        "for i in range(len(w)):\n",
        "    y_hat = w[i]*x + b;\n",
        "    j[i] = 0.5 * (y_hat - y)**2\n",
        "\n",
        "plt.plot(w,j, 'o' )\n",
        "plt.plot(w,j, 'r-' )\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKPc4SzH11T2"
      },
      "outputs": [],
      "source": [
        "import numpy as np   # numeriacal computing\n",
        "import matplotlib.pyplot as plt  # plotting core\n",
        "\n",
        "w = 1\n",
        "b = np.linspace(-3,3,100)\n",
        "\n",
        "j = np.zeros(100)\n",
        "for i in range(len(b)):\n",
        "    y_hat = w*2 + b[i];\n",
        "    j[i] = 0.5 * (y_hat - 2)**2\n",
        "\n",
        "plt.plot(b,j, 'o' )\n",
        "plt.plot(b,j, 'r-' )\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "PE2esdkX11T3"
      },
      "outputs": [],
      "source": [
        "import numpy as np   # numeriacal computing\n",
        "import matplotlib.pyplot as plt  # plotting core\n",
        "\n",
        "# simple function to demo step size\n",
        "def f(x) : # A parabola\n",
        "    f = 0.5*(2-x*2)**2\n",
        "    return f\n",
        "def Df(x) : # The derivative (gradient)\n",
        "    Df = 2*(2-x*2)\n",
        "    return Df\n",
        "def xp1(x,alpha) : # update\n",
        "    xp1 = x + alpha * Df(x)\n",
        "    return xp1\n",
        "\n",
        "def plot_steps( guess, alpha, nsteps) :\n",
        "    fig, ax = plt.subplots()\n",
        "    x = np.linspace(-1,3,100)\n",
        "    ax.plot(x, f(x))\n",
        "    x = guess\n",
        "    ax.plot(x,f(x), 'o', label='start x=%.2f' %x )\n",
        "    for i in range(nsteps):\n",
        "        xold = x\n",
        "        x = xp1(x,alpha)\n",
        "        #ax.plot(x,f(x), 'o', label='x = %.2f' %x)\n",
        "        ax.plot(x,f(x), 'o')\n",
        "        ax.plot([xold,x],[f(xold),f(x)], '-')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_steps(3, 0.03, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "u9zXFaIL11T3"
      },
      "outputs": [],
      "source": [
        "import numpy as np   # numeriacal computing\n",
        "import matplotlib.pyplot as plt  # plotting core\n",
        "\n",
        "# simple function to demo step size\n",
        "def f(x) : # A parabola\n",
        "    f = 0.5*x**2\n",
        "    return f\n",
        "def Df(x) : # The derivative (gradient)\n",
        "    Df = (-x)*2\n",
        "    return Df\n",
        "def xp1(x,alpha) : # update\n",
        "    xp1 = x + alpha * Df(x)\n",
        "    return xp1\n",
        "\n",
        "def plot_steps( guess, alpha, nsteps) :\n",
        "    fig, ax = plt.subplots()\n",
        "    x = np.linspace(-3,3,100)\n",
        "    ax.plot(x, f(x))\n",
        "    x = guess\n",
        "    ax.plot(x,f(x), 'o', label='start x=%.2f' %x )\n",
        "    for i in range(nsteps):\n",
        "        xold = x\n",
        "        x = xp1(x,alpha)\n",
        "        #ax.plot(x,f(x), 'o', label='x = %.2f' %x)\n",
        "        ax.plot(x,f(x), 'o')\n",
        "        ax.plot([xold,x],[f(xold),f(x)], '-')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_steps( -3, 0.03, 100 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyNLwn6911T3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "a0 = np.linspace(1,5,5)\n",
        "# print(a0)\n",
        "a1 = np.linspace(1,5,5)\n",
        "# print(a1)\n",
        "# plt.plot(a0, a1)\n",
        "aa0, aa1 = np.meshgrid(a0, a1)\n",
        "print(aa0)\n",
        "print(aa1)\n",
        "plt.plot(aa0, aa1 , 'o')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ybap9BgB11T4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# The function J\n",
        "def J(a0, a1, x, y, m):\n",
        "    ret=0\n",
        "    for i in range(m):\n",
        "        ret += 0.5*((a0 + a1*x[i]) - y[i] )**2\n",
        "    return ret/m\n",
        "\n",
        "x = np.linspace(-1,1,5)\n",
        "y = x\n",
        "\n",
        "#y = np.array([0.21378624, 1.97217916, 2.36737375, 5.13718724, 6.26470731])\n",
        "a0 = np.linspace(-3,3,100)\n",
        "a1 = np.linspace(-3,3,100)\n",
        "aa0, aa1 = np.meshgrid(a0, a1)\n",
        "plt.contour(aa0,aa1,J(aa0,aa1,x,y,m=len(x)) , colors='C0', levels=[i for i in np.arange(0,80,0.3)])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VQ8FqVm11T4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1,1,1,projection='3d')\n",
        "\n",
        "def pprint(arr):\n",
        "    print(\"type:{}\".format(type(arr)))\n",
        "    print(\"shape: {}, dimension: {}, dtype:{}\".format(arr.shape, arr.ndim, arr.dtype))\n",
        "    print(\"Array's Data:\\n\", arr)\n",
        "\n",
        "# The function J\n",
        "def J(a0, a1, x, y, m):\n",
        "    ret=0\n",
        "    for i in range(m):\n",
        "        ret += 0.5*((a0 + a1*x[i]) - y[i] )**2\n",
        "    return ret/m\n",
        "\n",
        "x = np.linspace(-1,1,5)\n",
        "y = x\n",
        "#y = np.array([0.21378624, 1.97217916, 2.36737375, 5.13718724, 6.26470731])\n",
        "a0 = np.linspace(-3,3,100)\n",
        "a1 = np.linspace(-3,3,100)\n",
        "\n",
        "#pprint(x)\n",
        "#pprint(y)\n",
        "#pprint(a0)\n",
        "\n",
        "#plt.plot(a1, J(a0,a1,x,y,m=len(x)) ) # set a0 to 0.1\n",
        "aa0, aa1 = np.meshgrid(a0, a1)\n",
        "ax.plot_surface(aa0, aa1, J(aa0,aa1,x,y,m=len(x)))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cizkmtSC11T4"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "diabetes = load_diabetes()\n",
        "import matplotlib.pyplot as plt\n",
        "# print(diabetes)\n",
        "# print(diabetes.data.shape)\n",
        "# print(diabetes.target.shape)\n",
        "x = diabetes.data[:, 2]\n",
        "# print(x)\n",
        "y = diabetes.target\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPeAWpny11T4"
      },
      "outputs": [],
      "source": [
        "w = 1.0\n",
        "b = 1.0\n",
        "for x_i, y_i in zip(x, y):\n",
        "    y_hat = x_i * w + b\n",
        "    err = y_hat - y_i\n",
        "    rate = 0.01\n",
        "    w = w - rate * err * x\n",
        "    b = b - rate * err\n",
        "\n",
        "plt.scatter(x, y)\n",
        "print(w)\n",
        "pt1 = (-0.1, -0.1 * w + b)\n",
        "pt2 = (0.15, 0.15 * w + b)\n",
        "plt.plot([pt1[0], pt2[0]], [pt1[1], pt2[1]], 'r-')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl3PJVCy11T4"
      },
      "outputs": [],
      "source": [
        "w = 1.0\n",
        "b = 1.0\n",
        "for i in range(1, 1000):\n",
        "    for x_i, y_i in zip(x, y):\n",
        "        y_hat = x_i * w + b\n",
        "        err = y_hat - y_i\n",
        "        rate = 0.01\n",
        "        w = w - rate * err * x_i\n",
        "        b = b - rate * err\n",
        "plt.scatter(x, y)\n",
        "# print(type(w))\n",
        "# print(w.shape)\n",
        "# print(w)\n",
        "# print(b)\n",
        "pt1 = (-0.1, -0.1 * w + b)\n",
        "pt2 = (0.15, 0.15 * w + b)\n",
        "plt.plot([pt1[0], pt2[0]], [pt1[1], pt2[1]], 'r-')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tOUx-Rt11T4"
      },
      "source": [
        "#### 값 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK8g9xXF11T5"
      },
      "outputs": [],
      "source": [
        "x_new = 0.18\n",
        "y_pred = x_new * w + b\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "P4BHb_PC11T5"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x, y)\n",
        "plt.scatter(x_new, y_pred)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKLsrvkh11T5"
      },
      "source": [
        "#### 뉴런으로 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf4pSs_f11T6"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.w = 1.0     # 가중치를 초기화합니다\n",
        "        self.b = 1.0     # 절편을 초기화합니다\n",
        "\n",
        "    def forpass(self, x):\n",
        "        y_hat = x * self.w + self.b       # 직선 방정식을 계산합니다\n",
        "        return y_hat\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        w_grad = x * err    # 가중치에 대한 그래디언트를 계산합니다\n",
        "        b_grad = 1 * err    # 절편에 대한 그래디언트를 계산합니다\n",
        "        return w_grad, b_grad\n",
        "\n",
        "    def fit(self, x, y, epochs=100):\n",
        "        for i in range(epochs):           # 에포크만큼 반복합니다\n",
        "            for x_i, y_i in zip(x, y):    # 모든 샘플에 대해 반복합니다\n",
        "                y_hat = self.forpass(x_i) # 정방향 계산\n",
        "                err = y_hat - y_i      # 오차 계산\n",
        "                w_grad, b_grad = self.backprop(x_i, err)  # 역방향 계산\n",
        "                self.w -= w_grad          # 가중치 업데이트\n",
        "                self.b -= b_grad          # 절편 업데이트\n",
        "\n",
        "neuron = Neuron()\n",
        "neuron.fit(x, y, 1000)\n",
        "\n",
        "plt.scatter(x, y)\n",
        "pt1 = (-0.1, -0.1 * neuron.w + neuron.b)\n",
        "pt2 = (0.15, 0.15 * neuron.w + neuron.b)\n",
        "plt.plot([pt1[0], pt2[0]], [pt1[1], pt2[1]],'r')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TFXwGoN11T6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as  plt\n",
        "import numpy as np\n",
        "\n",
        "class Neuron:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.w = 1.0     # 가중치를 초기화합니다\n",
        "        self.b = 1.0     # 절편을 초기화합니다\n",
        "\n",
        "    def forpass(self, x):\n",
        "        y_hat = x * self.w + self.b       # 직선 방정식을 계산합니다\n",
        "        return y_hat\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        w_grad = x * err    # 가중치에 대한 그래디언트를 계산합니다\n",
        "        b_grad = 1 * err    # 절편에 대한 그래디언트를 계산합니다\n",
        "        return w_grad, b_grad\n",
        "\n",
        "    def activation(self, z):\n",
        "        return z\n",
        "\n",
        "    def fit(self, x, y, epochs=200):\n",
        "        for i in range(epochs):           # 에포크만큼 반복합니다\n",
        "            for x_i, y_i in zip(x, y):    # 모든 샘플에 대해 반복합니다\n",
        "                y_hat = self.forpass(x_i) # 정방향 계산\n",
        "                y_hat = self.activation(y_hat)\n",
        "                err = y_hat - y_i      # 오차 계산\n",
        "                w_grad, b_grad = self.backprop(x_i, err)  # 역방향 계산\n",
        "                self.w -= 0.01*w_grad          # 가중치 업데이트\n",
        "                self.b -= 0.01*b_grad          # 절편 업데이트\n",
        "\n",
        "# x = np.array([1,2,3,4,5,6,7,8])\n",
        "# y = np.array([0,0,0,0,1,1,1,1])\n",
        "x = np.array([1,2,3,4,5,6,7,8,12])\n",
        "y = np.array([0,0,0,0,1,1,1,1,1])\n",
        "\n",
        "neuron = Neuron()\n",
        "neuron.fit(x, y)\n",
        "\n",
        "for xi, yi in zip(x,y):\n",
        "    plt.plot(xi,yi,\"rx\")\n",
        "\n",
        "y_temp = []\n",
        "for x_i in x:\n",
        "    y_hat = neuron.forpass(x_i)\n",
        "    if( y_hat >= 0.5 ):\n",
        "        print(\"%d : 악성종양\"%x_i)\n",
        "    else:\n",
        "        print(\"%d : 양성종양\"%x_i)\n",
        "    y_temp.append(y_hat)\n",
        "\n",
        "plt.plot(x,y_temp)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uTY79RF11T6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(42)\n",
        "probs = np.arange(0, 1, 0.01)\n",
        "probs\n",
        "odds = [p/(1-p) for p in probs]\n",
        "odds\n",
        "plt.plot(probs, odds)\n",
        "plt.xlabel('p')\n",
        "plt.ylabel('p/(1-p)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82K3Xdpv11T6"
      },
      "outputs": [],
      "source": [
        "probs  = np.arange(0.001, 0.999, 0.001)\n",
        "logit = [np.log(p/(1-p)) for p in probs]\n",
        "plt.plot(probs, logit)\n",
        "plt.xlabel('p')\n",
        "plt.ylabel('log(p/(1-p))')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8joJP7z11T6"
      },
      "outputs": [],
      "source": [
        "zs = np.arange(-10., 10., 0.1)\n",
        "gs = [1/(1+np.exp(-z)) for z in zs]\n",
        "plt.plot(zs, gs)\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('1/(1+e^-z)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycnuR1kC11T6"
      },
      "outputs": [],
      "source": [
        "zs = np.arange(0.01, 10., 0.01)\n",
        "gs = [-np.log(z) for z in zs]\n",
        "plt.plot(zs, gs)\n",
        "plt.xlim(0,1)\n",
        "plt.ylim(0,5)\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('(-np.log(z)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUgIjfKu11T6"
      },
      "outputs": [],
      "source": [
        "zs = np.arange(0.01, 10., 0.01)\n",
        "gs = [-np.log(1-z) for z in zs]\n",
        "plt.plot(zs, gs)\n",
        "plt.xlim(0,1)\n",
        "plt.ylim(0,5)\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('-(np.log(1-z)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnGS5weg11T6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as  plt\n",
        "import numpy as np\n",
        "\n",
        "class Neuron:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.w = 1.0     # 가중치를 초기화합니다\n",
        "        self.b = 1.0     # 절편을 초기화합니다\n",
        "\n",
        "    def forpass(self, x):\n",
        "        z = x * self.w + self.b       # 직선 방정식을 계산합니다\n",
        "        return z\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        w_grad = x * err    # 가중치에 대한 그래디언트를 계산합니다\n",
        "        b_grad = 1 * err    # 절편에 대한 그래디언트를 계산합니다\n",
        "        return w_grad, b_grad\n",
        "\n",
        "    def activation(self, z):\n",
        "#         a = z;\n",
        "        a = 1/(1+np.exp(-z))\n",
        "        return a\n",
        "\n",
        "    def fit(self, x, y, epochs=200):\n",
        "        for i in range(epochs):           # 에포크만큼 반복합니다\n",
        "            for x_i, y_i in zip(x, y):    # 모든 샘플에 대해 반복합니다\n",
        "                z = self.forpass(x_i) # 정방향 계산\n",
        "                a = self.activation(z)\n",
        "                err = a - y_i      # 오차 계산\n",
        "                w_grad, b_grad = self.backprop(x_i, err)  # 역방향 계산\n",
        "                self.w -= 0.1*w_grad          # 가중치 업데이트\n",
        "                self.b -= 0.1*b_grad          # 절편 업데이트\n",
        "\n",
        "# x = np.array([1,2,3,4,5,6,7,8])\n",
        "# y = np.array([0,0,0,0,1,1,1,1])\n",
        "x = np.array([1,2,3,4,5,6,7,8,12])\n",
        "y = np.array([0,0,0,0,1,1,1,1,1])\n",
        "\n",
        "neuron = Neuron()\n",
        "neuron.fit(x, y)\n",
        "\n",
        "for xi, yi in zip(x,y):\n",
        "    plt.plot(xi,yi,\"rx\")\n",
        "\n",
        "for x_i in x:\n",
        "    y_hat = neuron.forpass(x_i)\n",
        "    a = neuron.activation(y_hat)\n",
        "    if( a >= 0.5 ):\n",
        "        print(\"%d : 악성종양\"%x_i)\n",
        "    else:\n",
        "        print(\"%d : 양성종양\"%x_i)\n",
        "    y_temp.append(a)\n",
        "\n",
        "x = np.arange(0,x[-1],0.1)\n",
        "y_temp = []\n",
        "\n",
        "for i, x_i in enumerate(x):\n",
        "    y_hat = neuron.forpass(x_i)\n",
        "    a = neuron.activation(y_hat)\n",
        "    y_temp.append(a)\n",
        "\n",
        "plt.plot(x,y_temp)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-YlIsVM11T6"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "print(cancer.data.shape, cancer.target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjlW4Ult11T6"
      },
      "outputs": [],
      "source": [
        "cancer.data[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1ihHK0h11T6"
      },
      "outputs": [],
      "source": [
        "plt.boxplot(cancer.data)\n",
        "plt.xlabel('feature')\n",
        "plt.ylabel('value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXIoVViW11T6"
      },
      "outputs": [],
      "source": [
        "cancer.feature_names[[3,23]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqqSYRP411T6"
      },
      "outputs": [],
      "source": [
        "np.unique(cancer.target, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcpc9_Ax11T6"
      },
      "outputs": [],
      "source": [
        "x = cancer.data\n",
        "print(x.shape)\n",
        "y = cancer.target\n",
        "print(y.ndim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCXXPgb_11T7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_bGBShf11T7"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y,\n",
        "                                                    test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-Kky6l711T7"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape, x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC2bjTZv11T7"
      },
      "outputs": [],
      "source": [
        "np.unique(y_train, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYhRL7cl11T7"
      },
      "outputs": [],
      "source": [
        "print(x.shape[1])\n",
        "w=np.ones(x.shape[1])\n",
        "print(w)\n",
        "temp = np.zeros((2,3))\n",
        "print(temp)\n",
        "temp1 = np.full((2,3),7)\n",
        "print(temp1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_uYVnA511T7"
      },
      "outputs": [],
      "source": [
        "# # a = \"hello\"\n",
        "# # b = \"world\"\n",
        "# # a + b\n",
        "\n",
        "# a = np.array([1,2,3])\n",
        "# b = np.array([3,4,5])\n",
        "# print(a+b) # 원소별 합\n",
        "\n",
        "# print(a*b) # 원소별 곱\n",
        "\n",
        "# print(np.sum(a*b))\n",
        "\n",
        "a = np.array([1,2,3])\n",
        "b = 3\n",
        "\n",
        "a*b   # [1,2,3]*3 => [1,2,3]*[3,3,3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrnNUoCv11T7"
      },
      "outputs": [],
      "source": [
        "class LogisticNeuron:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def forpass(self, x):\n",
        "        z = np.sum(x * self.w) + self.b  # 직선 방정식을 계산합니다\n",
        "        return z\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        w_grad = x * err    # 가중치에 대한 그래디언트를 계산합니다\n",
        "        b_grad = 1 * err    # 절편에 대한 그래디언트를 계산합니다\n",
        "        return w_grad, b_grad\n",
        "\n",
        "    def activation(self, z):\n",
        "        z = np.clip(z, -100, None) # 안전한 np.exp() 계산을 위해\n",
        "        a = 1 / (1 + np.exp(-z))  # 시그모이드 계산\n",
        "        return a\n",
        "\n",
        "    def fit(self, x, y, epochs=100):\n",
        "        self.w = np.ones(x.shape[1])      # 가중치를 초기화합니다.\n",
        "        self.b = 0                        # 절편을 초기화합니다.\n",
        "        # print(x.shape[1])\n",
        "        for i in range(epochs):           # epochs만큼 반복합니다\n",
        "            for x_i, y_i in zip(x, y):    # 모든 샘플에 대해 반복합니다\n",
        "                z = self.forpass(x_i)     # 정방향 계산\n",
        "                a = self.activation(z)    # 활성화 함수 적용\n",
        "                err = (a - y_i)          # 오차 계산\n",
        "                w_grad, b_grad = self.backprop(x_i, err) # 역방향 계산\n",
        "                self.w -= w_grad          # 가중치 업데이트\n",
        "                self.b -= b_grad          # 절편 업데이트\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = [self.forpass(x_i) for x_i in x]    # 정방향 계산\n",
        "        a = self.activation(np.array(z))        # 활성화 함수 적용\n",
        "        return a >= 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4mJQORp11T7"
      },
      "outputs": [],
      "source": [
        "neuron = LogisticNeuron()\n",
        "neuron.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rwv1EwhX11T7"
      },
      "outputs": [],
      "source": [
        "# print(neuron.predict(x_test))\n",
        "print(neuron.predict(x_test)== y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-VtJlBq11T-"
      },
      "outputs": [],
      "source": [
        "np.mean(neuron.predict(x_test) == y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUW9XSpt11T-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x=np.array([0,1,2,3,4,5,6,7,8,9])\n",
        "# len(x)\n",
        "# x.shape[0]\n",
        "np.arange(len(x))\n",
        "indexes = np.random.permutation(np.arange(len(x)))\n",
        "for i in indexes:\n",
        "    print(x[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6BZwM2h11T_"
      },
      "outputs": [],
      "source": [
        "# temp = np.array([1,2,3,4])\n",
        "# mean = np.mean(temp)\n",
        "# print(mean)\n",
        "# mean = np.mean(temp, axis=0)\n",
        "# print(mean)\n",
        "\n",
        "\n",
        "temp = np.array([[1,2],\n",
        "                 [3,4]])\n",
        "# mean = np.mean(temp)\n",
        "# print(mean.shape)\n",
        "mean = np.mean(temp, axis=1)\n",
        "print(mean.ndim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0P8vRi511T_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "x = cancer.data\n",
        "y = cancer.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y,\n",
        "                                                    test_size=0.2, random_state=42)\n",
        "'''\n",
        "train_mean = np.mean(x_train, axis=0)  # 행렬의 열평균\n",
        "train_std = np.std(x_train, axis=0) # 행렬의 열 표준편차\n",
        "x_train_scaled = (x_train - train_mean) / train_std\n",
        "print(x_train_scaled)\n",
        "'''\n",
        "\n",
        "class SingleLayer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "        self.losses = []\n",
        "\n",
        "    def forpass(self, x):\n",
        "        z = np.sum(x * self.w) + self.b  # 직선 방정식을 계산합니다\n",
        "        return z\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        w_grad = x * err    # 가중치에 대한 그래디언트를 계산합니다\n",
        "        b_grad = 1 * err    # 절편에 대한 그래디언트를 계산합니다\n",
        "        return w_grad, b_grad\n",
        "\n",
        "    def activation(self, z):\n",
        "        z = np.clip(z, -100, None) # 안전한 np.exp() 계산을 위해\n",
        "        a = 1 / (1 + np.exp(-z))  # 시그모이드 계산\n",
        "        return a\n",
        "\n",
        "    def fit(self, x, y, epochs=100):\n",
        "        self.w = np.ones(x.shape[1])               # 가중치를 초기화합니다.\n",
        "        self.b = 0                                 # 절편을 초기화합니다.\n",
        "        for i in range(epochs):                    # epochs만큼 반복합니다\n",
        "            loss = 0\n",
        "            # 인덱스를 섞습니다\n",
        "            indexes = np.random.permutation(np.arange(len(x)))\n",
        "            for i in indexes:                      # 모든 샘플에 대해 반복합니다\n",
        "                z = self.forpass(x[i])             # 정방향 계산\n",
        "                a = self.activation(z)             # 활성화 함수 적용\n",
        "                err = -(y[i] - a)                  # 오차 계산\n",
        "                w_grad, b_grad = self.backprop(x[i], err) # 역방향 계산\n",
        "                self.w -= w_grad                   # 가중치 업데이트\n",
        "                self.b -= b_grad                   # 절편 업데이트\n",
        "                # 안전한 로그 계산을 위해 클리핑한 후 손실을 누적합니다\n",
        "                a = np.clip(a, 1e-10, 1-1e-10)\n",
        "                loss += -(y[i]*np.log(a)+(1-y[i])*np.log(1-a))\n",
        "            # 에포크마다 평균 손실을 저장합니다\n",
        "            self.losses.append(loss/len(y))\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = [self.forpass(x_i) for x_i in x]     # 정방향 계산\n",
        "        return np.array(z) > 0                   # 스텝 함수 적용\n",
        "\n",
        "    def score(self, x, y):\n",
        "        return np.mean(self.predict(x) == y)\n",
        "\n",
        "layer = SingleLayer()\n",
        "layer.fit(x_train, y_train)\n",
        "layer.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-vJq5sW11T_"
      },
      "outputs": [],
      "source": [
        "plt.plot(layer.losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP69Chkq11T_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "cancer = load_breast_cancer()\n",
        "x = cancer.data\n",
        "y = cancer.target\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify=y,\n",
        "                                                            test_size=0.2, random_state=42)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all,\n",
        "                                                  test_size=0.2, random_state=42)\n",
        "print(len(x_train), len(x_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVNCJVLa11T_"
      },
      "outputs": [],
      "source": [
        "print(cancer.feature_names[[2,3]])\n",
        "plt.boxplot(x_train[:, 2:4])\n",
        "plt.xlabel('feature')\n",
        "plt.ylabel('value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfUZiV3q11T_"
      },
      "outputs": [],
      "source": [
        "class SingleLayer:\n",
        "\n",
        "    def __init__(self, learning_rate=0.1, l1=0, l2=0):\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.w_history = []\n",
        "        self.lr = learning_rate\n",
        "        self.l1 = l1\n",
        "        self.l2 = l2\n",
        "\n",
        "    def forpass(self, x):\n",
        "        z = np.sum(x * self.w) + self.b    # 직선 방정식을 계산합니다\n",
        "        return z\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        w_grad = x * err          # 가중치에 대한 그래디언트를 계산합니다\n",
        "        b_grad = 1 * err    # 절편에 대한 그래디언트를 계산합니다\n",
        "        return w_grad, b_grad\n",
        "\n",
        "    def activation(self, z):\n",
        "        z = np.clip(z, -100, None) # 안전한 np.exp() 계산을 위해\n",
        "        a = 1 / (1 + np.exp(-z))  # 시그모이드 계산\n",
        "        return a\n",
        "\n",
        "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
        "        self.w = np.ones(x.shape[1])               # 가중치를 초기화합니다.\n",
        "        self.b = 0                                 # 절편을 초기화합니다.\n",
        "        self.w_history.append(self.w.copy())       # 가중치를 기록합니다.\n",
        "        np.random.seed(42)                         # 랜덤 시드를 지정합니다.\n",
        "        for i in range(epochs):                    # epochs만큼 반복합니다.\n",
        "            loss = 0\n",
        "            # 인덱스를 섞습니다\n",
        "            indexes = np.random.permutation(np.arange(len(x)))\n",
        "            for i in indexes:                      # 모든 샘플에 대해 반복합니다\n",
        "                z = self.forpass(x[i])             # 정방향 계산\n",
        "                a = self.activation(z)             # 활성화 함수 적용\n",
        "                err = -(y[i] - a)                  # 오차 계산\n",
        "                w_grad, b_grad = self.backprop(x[i], err) # 역방향 계산\n",
        "                # 그래디언트에서 페널티 항의 미분 값을 더합니다\n",
        "                w_grad += self.l1 * np.sign(self.w) + self.l2 * self.w\n",
        "                self.w -= self.lr * w_grad         # 가중치 업데이트\n",
        "                self.b -= b_grad                   # 절편 업데이트\n",
        "                # 가중치를 기록합니다.\n",
        "                self.w_history.append(self.w.copy())\n",
        "                # 안전한 로그 계산을 위해 클리핑한 후 손실을 누적합니다\n",
        "                a = np.clip(a, 1e-10, 1-1e-10)\n",
        "                loss += -(y[i]*np.log(a)+(1-y[i])*np.log(1-a))\n",
        "            # 에포크마다 평균 손실을 저장합니다\n",
        "            self.losses.append(loss/len(y) + self.reg_loss())\n",
        "            # 검증 세트에 대한 손실을 계산합니다\n",
        "            self.update_val_loss(x_val, y_val)\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = [self.forpass(x_i) for x_i in x]     # 정방향 계산\n",
        "        return np.array(z) >= 0                   # 스텝 함수 적용\n",
        "\n",
        "    def score(self, x, y):\n",
        "        return np.mean(self.predict(x) == y)\n",
        "\n",
        "    def reg_loss(self):\n",
        "        return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w**2)\n",
        "\n",
        "    def update_val_loss(self, x_val, y_val):\n",
        "        if x_val is None:\n",
        "            return\n",
        "        val_loss = 0\n",
        "        for i in range(len(x_val)):\n",
        "            z = self.forpass(x_val[i])     # 정방향 계산\n",
        "            a = self.activation(z)         # 활성화 함수 적용\n",
        "            a = np.clip(a, 1e-10, 1-1e-10)\n",
        "            val_loss += -(y_val[i]*np.log(a)+(1-y_val[i])*np.log(1-a))\n",
        "        self.val_losses.append(val_loss/len(y_val) + self.reg_loss())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDQ1Zn6L11T_"
      },
      "outputs": [],
      "source": [
        "layer1 = SingleLayer()\n",
        "layer1.fit(x_train, y_train)\n",
        "layer1.score(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXmQ-52n11T_"
      },
      "outputs": [],
      "source": [
        "w2 = []\n",
        "w3 = []\n",
        "for w in layer1.w_history:\n",
        "    w2.append(w[2])\n",
        "    w3.append(w[3])\n",
        "plt.plot(w2, w3)\n",
        "plt.plot(w2[-1], w3[-1], 'ro')\n",
        "plt.xlabel('w[2]')\n",
        "plt.ylabel('w[3]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFb2v7_311T_"
      },
      "outputs": [],
      "source": [
        "train_mean = np.mean(x_train, axis=0)\n",
        "train_std = np.std(x_train, axis=0)\n",
        "x_train_scaled = (x_train - train_mean) / train_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYE1Vwsc11T_"
      },
      "outputs": [],
      "source": [
        "layer2 = SingleLayer()\n",
        "layer2.fit(x_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WCn7Dwt11T_"
      },
      "outputs": [],
      "source": [
        "w2 = []\n",
        "w3 = []\n",
        "for w in layer2.w_history:\n",
        "    w2.append(w[2])\n",
        "    w3.append(w[3])\n",
        "plt.plot(w2, w3)\n",
        "plt.plot(w2[-1], w3[-1], 'ro')\n",
        "plt.xlabel('w[2]')\n",
        "plt.ylabel('w[3]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seCxdqPT11T_"
      },
      "outputs": [],
      "source": [
        "layer2.score(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVEToetn11T_"
      },
      "outputs": [],
      "source": [
        "val_mean = np.mean(x_val, axis=0)\n",
        "val_std = np.std(x_val, axis=0)\n",
        "x_val_scaled = (x_val - val_mean) / val_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGBklsT111T_"
      },
      "outputs": [],
      "source": [
        "layer2.score(x_val_scaled, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gNTPbxu11UA"
      },
      "outputs": [],
      "source": [
        "layer3 = SingleLayer()\n",
        "layer3.fit(x_train_scaled, y_train, x_val=x_val_scaled, y_val=y_val)\n",
        "\n",
        "plt.ylim(0, 0.3)\n",
        "plt.plot(layer3.losses)\n",
        "plt.plot(layer3.val_losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbbM4Xs311UA"
      },
      "outputs": [],
      "source": [
        "layer4 = SingleLayer()\n",
        "layer4.fit(x_train_scaled, y_train, epochs=20)\n",
        "layer4.score(x_val_scaled, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfvJqU_f11UA"
      },
      "outputs": [],
      "source": [
        "l1_list = [0.0001, 0.001, 0.01]\n",
        "\n",
        "for l1 in l1_list:\n",
        "    lyr = SingleLayer(l1=l1)\n",
        "    lyr.fit(x_train_scaled, y_train, x_val=x_val_scaled, y_val=y_val)\n",
        "\n",
        "    plt.plot(lyr.losses)\n",
        "    plt.plot(lyr.val_losses)\n",
        "    plt.title('Learning Curve (l1={})'.format(l1))\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'val_loss'])\n",
        "    plt.ylim(0, 0.3)\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(lyr.w, 'bo')\n",
        "    plt.title('Weight (l1={})'.format(l1))\n",
        "    plt.ylabel('value')\n",
        "    plt.xlabel('weight')\n",
        "    plt.ylim(-4, 4)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qqMAECe11UA"
      },
      "outputs": [],
      "source": [
        "l2_list = [0.0001, 0.001, 0.01]\n",
        "\n",
        "for l2 in l2_list:\n",
        "    lyr = SingleLayer(l2=l2)\n",
        "    lyr.fit(x_train_scaled, y_train, x_val=x_val_scaled, y_val=y_val)\n",
        "\n",
        "    plt.plot(lyr.losses)\n",
        "    plt.plot(lyr.val_losses)\n",
        "    plt.title('Learning Curve (l2={})'.format(l2))\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'val_loss'])\n",
        "    plt.ylim(0, 0.3)\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(lyr.w, 'bo')\n",
        "    plt.title('Weight (l2={})'.format(l2))\n",
        "    plt.ylabel('value')\n",
        "    plt.xlabel('weight')\n",
        "    plt.ylim(-4, 4)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psxIylmD11UA"
      },
      "outputs": [],
      "source": [
        "validation_scores = []\n",
        "k = 10\n",
        "bins = len(x_train_all) // k\n",
        "\n",
        "for i in range(k):\n",
        "    start = i*bins\n",
        "    end = (i+1)*bins\n",
        "    val_fold = x_train_all[start:end]\n",
        "    val_target = y_train_all[start:end]\n",
        "\n",
        "    train_index = list(range(0, start))+list(range(end, len(x_train)))\n",
        "    train_fold = x_train_all[train_index]\n",
        "    train_target = y_train_all[train_index]\n",
        "\n",
        "    train_mean = np.mean(train_fold, axis=0)\n",
        "    train_std = np.std(train_fold, axis=0)\n",
        "    train_fold_scaled = (train_fold - train_mean) / train_std\n",
        "    val_fold_scaled = (val_fold - train_mean) / train_std\n",
        "\n",
        "    lyr = SingleLayer(l2=0.01)\n",
        "    lyr.fit(train_fold_scaled, train_target, epochs=50)\n",
        "    score = lyr.score(val_fold_scaled, val_target)\n",
        "    validation_scores.append(score)\n",
        "\n",
        "print(np.mean(validation_scores))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3])\n",
        "b = np.array([2,2,2])\n",
        "# np.sum(a*b)\n",
        "np.dot(a,b)"
      ],
      "metadata": {
        "id": "6nVCNbjP7fbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3])\n",
        "b = np.array([[1,2],\n",
        "              [1,2],\n",
        "              [1,2]])\n",
        "\n",
        "np.dot(a,b)   # (3,)(3,2)=>(2,)"
      ],
      "metadata": {
        "id": "G-zQsg5_9-z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2],\n",
        "              [1,2],\n",
        "              [1,2]])\n",
        "b = np.array([1,2])\n",
        "\n",
        "np.dot(a,b)   # (3,2)(2,)=>(3,)"
      ],
      "metadata": {
        "id": "kMl01VLJ-8BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2],\n",
        "              [1,2],\n",
        "              [1,2]])\n",
        "b = np.array([[1],\n",
        "              [2]])\n",
        "\n",
        "np.dot(a,b)   # (3,2)(2,1)=>(3,1)"
      ],
      "metadata": {
        "id": "AQ9Mm2yz_hy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2],\n",
        "              [3,4]])\n",
        "b = np.array([[1,2],\n",
        "              [1,2]])\n",
        "np.dot(a,b)"
      ],
      "metadata": {
        "id": "UlJxibeUARaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLy-q4EG11UA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V9IEy7e11UA"
      },
      "outputs": [],
      "source": [
        "cancer = load_breast_cancer()\n",
        "x = cancer.data\n",
        "y = cancer.target\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify=y,\n",
        "                                                            test_size=0.2, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all,\n",
        "                                                  test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-Iu2SYn11UA"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape, x_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DOceaZK11UA"
      },
      "outputs": [],
      "source": [
        "class SingleLayer:\n",
        "\n",
        "    def __init__(self, learning_rate=0.1, l1=0, l2=0):\n",
        "        self.w = None              # 가중치\n",
        "        self.b = None              # 절편\n",
        "        self.losses = []           # 훈련 손실\n",
        "        self.val_losses = []       # 검증 손실\n",
        "        self.w_history = []        # 가중치 기록\n",
        "        self.lr = learning_rate    # 학습률\n",
        "        self.l1 = l1               # L1 손실 하이퍼파라미터\n",
        "        self.l2 = l2               # L2 손실 하이퍼파라미터\n",
        "\n",
        "    def forpass(self, x):\n",
        "        z = np.dot(x, self.w) + self.b        # 선형 출력을 계산합니다.\n",
        "        #       (364,30)(30,1) => (364,1)+() => (364,1)+(364,1)\n",
        "        return z\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        m = len(x)\n",
        "        w_grad = np.dot(x.T, err) / m         # 가중치에 대한 그래디언트를 계산합니다.\n",
        "        b_grad = np.sum(err) / m              # 절편에 대한 그래디언트를 계산합니다.\n",
        "        return w_grad, b_grad\n",
        "\n",
        "    def activation(self, z):\n",
        "        z = np.clip(z, -100, None)            # 안전한 np.exp() 계산을 위해\n",
        "        a = 1 / (1 + np.exp(-z))              # 시그모이드 계산\n",
        "        return a\n",
        "\n",
        "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
        "        y = y.reshape(-1, 1)                  # 타깃을 열 벡터로 바꿉니다.\n",
        "        y_val = y_val.reshape(-1, 1)\n",
        "        m = len(x)                            # 샘플 개수를 저장합니다.\n",
        "        self.w = np.ones((x.shape[1], 1))     # 가중치를 초기화합니다.\n",
        "        self.b = 0                            # 절편을 초기화합니다.\n",
        "        self.w_history.append(self.w.copy())  # 가중치를 기록합니다.\n",
        "        # epochs만큼 반복합니다.\n",
        "        for i in range(epochs):\n",
        "            z = self.forpass(x)               # 정방향 계산을 수행합니다.\n",
        "            a = self.activation(z)            # 활성화 함수를 적용합니다.\n",
        "            err = -(y - a)                    # 오차를 계산합니다.\n",
        "            # 오차를 역전파하여 그래디언트를 계산합니다.\n",
        "            w_grad, b_grad = self.backprop(x, err)\n",
        "            # 그래디언트에서 페널티 항의 미분 값을 더합니다.\n",
        "            w_grad += (self.l1 * np.sign(self.w) + self.l2 * self.w) / m\n",
        "            # 가중치와 절편을 업데이트합니다.\n",
        "            self.w -= self.lr * w_grad\n",
        "            self.b -= self.lr * b_grad\n",
        "            # 가중치를 기록합니다.\n",
        "            self.w_history.append(self.w.copy())\n",
        "            # 안전한 로그 계산을 위해 클리핑합니다.\n",
        "            a = np.clip(a, 1e-10, 1-1e-10)\n",
        "            # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
        "            loss = np.sum(-(y*np.log(a) + (1-y)*np.log(1-a)))\n",
        "            self.losses.append((loss + self.reg_loss()) / m)\n",
        "            # 검증 세트에 대한 손실을 계산합니다.\n",
        "            self.update_val_loss(x_val, y_val)\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = self.forpass(x)      # 정방향 계산을 수행합니다.\n",
        "        return z > 0             # 스텝 함수를 적용합니다.\n",
        "\n",
        "    def score(self, x, y):\n",
        "        # 예측과 타깃 열 벡터를 비교하여 True의 비율을 반환합니다.\n",
        "        return np.mean(self.predict(x) == y.reshape(-1, 1))\n",
        "\n",
        "    def reg_loss(self):\n",
        "        # 가중치에 규제를 적용합니다.\n",
        "        return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w**2)\n",
        "\n",
        "    def update_val_loss(self, x_val, y_val):\n",
        "        z = self.forpass(x_val)            # 정방향 계산을 수행합니다.\n",
        "        a = self.activation(z)             # 활성화 함수를 적용합니다.\n",
        "        a = np.clip(a, 1e-10, 1-1e-10)     # 출력 값을 클리핑합니다.\n",
        "        # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
        "        val_loss = np.sum(-(y_val*np.log(a) + (1-y_val)*np.log(1-a)))\n",
        "        self.val_losses.append((val_loss + self.reg_loss()) / len(y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTwcu2vF11UA"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfNePN_X11UB"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train_scaled = scaler.transform(x_train)\n",
        "x_val_scaled = scaler.transform(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6SK-wqj11UB"
      },
      "outputs": [],
      "source": [
        "single_layer = SingleLayer(l2=0.01)\n",
        "single_layer.fit(x_train_scaled, y_train,\n",
        "                 x_val=x_val_scaled, y_val=y_val, epochs=10000)\n",
        "single_layer.score(x_val_scaled, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41WrjWQf11UB"
      },
      "outputs": [],
      "source": [
        "plt.ylim(0, 0.3)\n",
        "plt.plot(single_layer.losses)\n",
        "plt.plot(single_layer.val_losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRVCxpPG11UB"
      },
      "outputs": [],
      "source": [
        "w2 = []\n",
        "w3 = []\n",
        "for w in single_layer.w_history:\n",
        "    w2.append(w[2])\n",
        "    w3.append(w[3])\n",
        "plt.plot(w2, w3)\n",
        "plt.plot(w2[-1], w3[-1], 'ro')\n",
        "plt.xlabel('w[2]')\n",
        "plt.ylabel('w[3]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGJhUcMp11UB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([[1,2],\n",
        "              [3,4]])\n",
        "b = np.array([[2,2],\n",
        "              [1,1]])\n",
        "\n",
        "print( np.dot(a,b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cqv4a4uc11UB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "temp = np.array([1,2,3,4,5])\n",
        "temp = temp.reshape(-1, 1)\n",
        "print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qj42Jr_x11UB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "temp = np.array([[1,2,3,4,5]])\n",
        "print(temp.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJThZ92811UB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "print(np.random.random(5))\n",
        "print(np.random.random(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDO4p4IF11UB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(100)\n",
        "print(np.random.random(5))\n",
        "print(np.random.random(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9Iop2uL11UB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(100)\n",
        "print(np.random.random((3,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzrqO17K11UB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(100)\n",
        "print(np.random.normal(0,1,(3,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URtlWW9511UB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "temp = np.random.normal(0,1,10000)\n",
        "print( np.mean(temp) )\n",
        "print( np.std(temp) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCG6tVdC11UB"
      },
      "outputs": [],
      "source": [
        "class DualLayer(SingleLayer):\n",
        "\n",
        "    def __init__(self, units=10, learning_rate=0.1, l1=0, l2=0):\n",
        "        self.units = units         # 은닉층의 뉴런 개수\n",
        "        self.w1 = None             # 은닉층의 가중치\n",
        "        self.b1 = None             # 은닉층의 절편\n",
        "        self.w2 = None             # 출력층의 가중치\n",
        "        self.b2 = None             # 출력층의 절편\n",
        "        self.a1 = None             # 은닉층의 활성화 출력\n",
        "        self.losses = []           # 훈련 손실\n",
        "        self.val_losses = []       # 검증 손실\n",
        "        self.lr = learning_rate    # 학습률\n",
        "        self.l1 = l1               # L1 손실 하이퍼파라미터\n",
        "        self.l2 = l2               # L2 손실 하이퍼파라미터\n",
        "\n",
        "    def forpass(self, x):\n",
        "        z1 = np.dot(x, self.w1) + self.b1        # 첫 번째 층의 선형 식을 계산합니다\n",
        "        self.a1 = self.activation(z1)            # 활성화 함수를 적용합니다\n",
        "        z2 = np.dot(self.a1, self.w2) + self.b2  # 두 번째 층의 선형 식을 계산합니다.\n",
        "        return z2\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        m = len(x)       # 샘플 개수\n",
        "        # 출력층의 가중치와 절편에 대한 그래디언트를 계산합니다.\n",
        "        w2_grad = np.dot(self.a1.T, err) / m\n",
        "        b2_grad = np.sum(err) / m\n",
        "        # 시그모이드 함수까지 그래디언트를 계산합니다.\n",
        "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\n",
        "        # 은닉층의 가중치와 절편에 대한 그래디언트를 계산합니다.\n",
        "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
        "        b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
        "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
        "\n",
        "    def init_weights(self, n_features):\n",
        "        self.w1 = np.ones((n_features, self.units))  # (특성 개수, 은닉층의 크기)\n",
        "        self.b1 = np.zeros(self.units)               # 은닉층의 크기\n",
        "        self.w2 = np.ones((self.units, 1))           # (은닉층의 크기, 1)\n",
        "        self.b2 = 0\n",
        "\n",
        "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
        "        y = y.reshape(-1, 1)          # 타깃을 열 벡터로 바꿉니다.\n",
        "        y_val = y_val.reshape(-1, 1)\n",
        "        m = len(x)                    # 샘플 개수를 저장합니다.\n",
        "        self.init_weights(x.shape[1]) # 은닉층과 출력층의 가중치를 초기화합니다.\n",
        "        # epochs만큼 반복합니다.\n",
        "        for i in range(epochs):\n",
        "            a = self.training(x, y, m)\n",
        "            # 안전한 로그 계산을 위해 클리핑합니다.\n",
        "            a = np.clip(a, 1e-10, 1-1e-10)\n",
        "            # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
        "            loss = np.sum(-(y*np.log(a) + (1-y)*np.log(1-a)))\n",
        "            self.losses.append((loss + self.reg_loss()) / m)\n",
        "            # 검증 세트에 대한 손실을 계산합니다.\n",
        "            self.update_val_loss(x_val, y_val)\n",
        "\n",
        "    def training(self, x, y, m):\n",
        "        z = self.forpass(x)       # 정방향 계산을 수행합니다.\n",
        "        a = self.activation(z)    # 활성화 함수를 적용합니다.\n",
        "        err = -(y - a)            # 오차를 계산합니다.\n",
        "        # 오차를 역전파하여 그래디언트를 계산합니다.\n",
        "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
        "        # 그래디언트에서 페널티 항의 미분 값을 뺍니다\n",
        "        w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\n",
        "        w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m\n",
        "        # 은닉층의 가중치와 절편을 업데이트합니다.\n",
        "        self.w1 -= self.lr * w1_grad\n",
        "        self.b1 -= self.lr * b1_grad\n",
        "        # 출력층의 가중치와 절편을 업데이트합니다.\n",
        "        self.w2 -= self.lr * w2_grad\n",
        "        self.b2 -= self.lr * b2_grad\n",
        "        return a\n",
        "\n",
        "    def reg_loss(self):\n",
        "        # 은닉층과 출력층의 가중치에 규제를 적용합니다.\n",
        "        return self.l1 * (np.sum(np.abs(self.w1)) + np.sum(np.abs(self.w2))) + \\\n",
        "               self.l2 / 2 * (np.sum(self.w1**2) + np.sum(self.w2**2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESsIpbUT11UB"
      },
      "outputs": [],
      "source": [
        "dual_layer = DualLayer(l2=0.01)\n",
        "dual_layer.fit(x_train_scaled, y_train,\n",
        "               x_val=x_val_scaled, y_val=y_val, epochs=20000)\n",
        "dual_layer.score(x_val_scaled, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP-fUT0F11UB"
      },
      "outputs": [],
      "source": [
        "plt.ylim(0, 0.3)\n",
        "plt.plot(dual_layer.losses)\n",
        "plt.plot(dual_layer.val_losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmJ1mHNM11UB"
      },
      "outputs": [],
      "source": [
        "class RandomInitNetwork(DualLayer):\n",
        "\n",
        "    def init_weights(self, n_features):\n",
        "        np.random.seed(42)\n",
        "        self.w1 = np.random.normal(0, 1,\n",
        "                                   (n_features, self.units))  # (특성 개수, 은닉층의 크기)\n",
        "        self.b1 = np.zeros(self.units)                        # 은닉층의 크기\n",
        "        self.w2 = np.random.normal(0, 1,\n",
        "                                   (self.units, 1))           # (은닉층의 크기, 1)\n",
        "        self.b2 = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JctiZDHK11UC"
      },
      "outputs": [],
      "source": [
        "random_init_net = RandomInitNetwork(l2=0.01)\n",
        "random_init_net.fit(x_train_scaled, y_train,\n",
        "                    x_val=x_val_scaled, y_val=y_val, epochs=500)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def foo():\n",
        "    print('foo()')\n",
        "    return 10\n",
        "    print('after')\n",
        "\n",
        "c = foo()\n",
        "print(c)"
      ],
      "metadata": {
        "id": "S8YVOdcXRT9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def foo():\n",
        "    print('foo()')\n",
        "    yield 10\n",
        "    print('after')\n",
        "\n",
        "c = foo()\n",
        "next(c)"
      ],
      "metadata": {
        "id": "sdYOr582RuTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def foo():\n",
        "    print('foo()')\n",
        "    yield 1\n",
        "    print('after')\n",
        "    yield 2\n",
        "\n",
        "c = foo()\n",
        "print(next(c))\n",
        "print(next(c))\n",
        "print(next(c))"
      ],
      "metadata": {
        "id": "bgt_zyr8SO22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def foo():\n",
        "    print('foo()')\n",
        "    yield 1\n",
        "    print('after')\n",
        "    yield 2\n",
        "\n",
        "c = foo()\n",
        "for data in c:\n",
        "    print(data)\n"
      ],
      "metadata": {
        "id": "RxVyBMLGSc_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def foo():\n",
        "    print('foo()')\n",
        "    for data in range(1,3):\n",
        "        yield data\n",
        "\n",
        "c = foo()\n",
        "for data in c:\n",
        "    print(data)"
      ],
      "metadata": {
        "id": "1KgSz8KuSqhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4cXtLuS11UC"
      },
      "outputs": [],
      "source": [
        "plt.plot(random_init_net.losses)\n",
        "plt.plot(random_init_net.val_losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anU7XXvO11UC"
      },
      "outputs": [],
      "source": [
        "class MinibatchNetwork(RandomInitNetwork):\n",
        "\n",
        "    def __init__(self, units=10, batch_size=32, learning_rate=0.1, l1=0, l2=0):\n",
        "        super().__init__(units, learning_rate, l1, l2)\n",
        "        self.batch_size = batch_size     # 배치 크기\n",
        "\n",
        "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
        "        y_val = y_val.reshape(-1, 1)     # 타깃을 열 벡터로 바꿉니다.\n",
        "        self.init_weights(x.shape[1])    # 은닉층과 출력층의 가중치를 초기화합니다.\n",
        "        np.random.seed(42)\n",
        "        # epochs만큼 반복합니다.\n",
        "        for i in range(epochs):\n",
        "            loss = 0\n",
        "            # 제너레이터 함수에서 반환한 미니배치를 순환합니다.\n",
        "            for x_batch, y_batch in self.gen_batch(x, y):\n",
        "                y_batch = y_batch.reshape(-1, 1) # 타깃을 열 벡터로 바꿉니다.\n",
        "                m = len(x_batch)                 # 샘플 개수를 저장합니다.\n",
        "                a = self.training(x_batch, y_batch, m)\n",
        "                # 안전한 로그 계산을 위해 클리핑합니다.\n",
        "                a = np.clip(a, 1e-10, 1-1e-10)\n",
        "                # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
        "                loss += np.sum(-(y_batch*np.log(a) + (1-y_batch)*np.log(1-a)))\n",
        "            self.losses.append((loss + self.reg_loss()) / len(x))\n",
        "            # 검증 세트에 대한 손실을 계산합니다.\n",
        "            self.update_val_loss(x_val, y_val)\n",
        "\n",
        "    # 미니배치 제너레이터 함수\n",
        "    def gen_batch(self, x, y):\n",
        "        length = len(x)\n",
        "        bins = length // self.batch_size # 미니배치 횟수\n",
        "        if length % self.batch_size:\n",
        "            bins += 1                    # 나누어 떨어지지 않을 때\n",
        "        indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞습니다.\n",
        "        x = x[indexes]\n",
        "        y = y[indexes]\n",
        "        for i in range(bins):\n",
        "            start = self.batch_size * i\n",
        "            end = self.batch_size * (i + 1)\n",
        "            yield x[start:end], y[start:end]   # batch_size만큼 슬라이싱하여 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1QfvRYc11UC"
      },
      "outputs": [],
      "source": [
        "minibatch_net = MinibatchNetwork(l2=0.01, batch_size=32)\n",
        "minibatch_net.fit(x_train_scaled, y_train,\n",
        "                  x_val=x_val_scaled, y_val=y_val, epochs=500)\n",
        "minibatch_net.score(x_val_scaled, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec9oVFPb11UC"
      },
      "outputs": [],
      "source": [
        "plt.plot(minibatch_net.losses)\n",
        "plt.plot(minibatch_net.val_losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iteration')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mm9SnNP611UC"
      },
      "outputs": [],
      "source": [
        "minibatch_net = MinibatchNetwork(l2=0.01, batch_size=128)\n",
        "minibatch_net.fit(x_train_scaled, y_train,\n",
        "                  x_val=x_val_scaled, y_val=y_val, epochs=500)\n",
        "minibatch_net.score(x_val_scaled, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTzAzbse11UC"
      },
      "outputs": [],
      "source": [
        "plt.plot(minibatch_net.losses)\n",
        "plt.plot(minibatch_net.val_losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iteration')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hfv95UGJ11UC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "temp = np.array([[2.20,1.39,0.85],\n",
        "                 [0.00,-1.39,-2.20]])\n",
        "exp_temp = np.exp(temp)\n",
        "ret = exp_temp / np.sum(exp_temp, axis=1).reshape(-1, 1)\n",
        "print( ret )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFmELkad11UC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class MultiClassNetwork:\n",
        "\n",
        "    def __init__(self, units=10, batch_size=32, learning_rate=0.1, l1=0, l2=0):\n",
        "        self.units = units         # 은닉층의 뉴런 개수\n",
        "        self.batch_size = batch_size     # 배치 크기\n",
        "        self.w1 = None             # 은닉층의 가중치\n",
        "        self.b1 = None             # 은닉층의 절편\n",
        "        self.w2 = None             # 출력층의 가중치\n",
        "        self.b2 = None             # 출력층의 절편\n",
        "        self.a1 = None             # 은닉층의 활성화 출력\n",
        "        self.losses = []           # 훈련 손실\n",
        "        self.val_losses = []       # 검증 손실\n",
        "        self.lr = learning_rate    # 학습률\n",
        "        self.l1 = l1               # L1 손실 하이퍼파라미터\n",
        "        self.l2 = l2               # L2 손실 하이퍼파라미터\n",
        "\n",
        "    def forpass(self, x):\n",
        "        z1 = np.dot(x, self.w1) + self.b1        # 첫 번째 층의 선형 식을 계산합니다\n",
        "        self.a1 = self.sigmoid(z1)               # 활성화 함수를 적용합니다\n",
        "        z2 = np.dot(self.a1, self.w2) + self.b2  # 두 번째 층의 선형 식을 계산합니다.\n",
        "        return z2\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        m = len(x)       # 샘플 개수\n",
        "        # 출력층의 가중치와 절편에 대한 그래디언트를 계산합니다.\n",
        "        w2_grad = np.dot(self.a1.T, err) / m\n",
        "        b2_grad = np.sum(err) / m\n",
        "        # 시그모이드 함수까지 그래디언트를 계산합니다.\n",
        "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\n",
        "        # 은닉층의 가중치와 절편에 대한 그래디언트를 계산합니다.\n",
        "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
        "        b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
        "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        z = np.clip(z, -100, None)            # 안전한 np.exp() 계산을 위해\n",
        "        a = 1 / (1 + np.exp(-z))              # 시그모이드 계산\n",
        "        return a\n",
        "\n",
        "    def softmax(self, z):\n",
        "        # 소프트맥스 함수\n",
        "        z = np.clip(z, -100, None)            # 안전한 np.exp() 계산을 위해\n",
        "        exp_z = np.exp(z)\n",
        "        return exp_z / np.sum(exp_z, axis=1).reshape(-1, 1)\n",
        "\n",
        "    def init_weights(self, n_features, n_classes):\n",
        "        self.w1 = np.random.normal(0, 1,\n",
        "                                   (n_features, self.units))  # (특성 개수, 은닉층의 크기)\n",
        "        self.b1 = np.zeros(self.units)                        # 은닉층의 크기\n",
        "        self.w2 = np.random.normal(0, 1,\n",
        "                                   (self.units, n_classes))   # (은닉층의 크기, 클래스 개수)\n",
        "        self.b2 = np.zeros(n_classes)\n",
        "\n",
        "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
        "        np.random.seed(42)\n",
        "        self.init_weights(x.shape[1], y.shape[1])    # 은닉층과 출력층의 가중치를 초기화합니다.\n",
        "        # epochs만큼 반복합니다.\n",
        "        for i in range(epochs):\n",
        "            loss = 0\n",
        "            print('.', end='')\n",
        "            # 제너레이터 함수에서 반환한 미니배치를 순환합니다.\n",
        "            for x_batch, y_batch in self.gen_batch(x, y):\n",
        "                a = self.training(x_batch, y_batch)\n",
        "                # 안전한 로그 계산을 위해 클리핑합니다.\n",
        "                a = np.clip(a, 1e-10, 1-1e-10)\n",
        "                # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
        "                loss += np.sum(-y_batch*np.log(a))\n",
        "            self.losses.append((loss + self.reg_loss()) / len(x))\n",
        "            # 검증 세트에 대한 손실을 계산합니다.\n",
        "            self.update_val_loss(x_val, y_val)\n",
        "\n",
        "    # 미니배치 제너레이터 함수\n",
        "    def gen_batch(self, x, y):\n",
        "        length = len(x)\n",
        "        bins = length // self.batch_size # 미니배치 횟수\n",
        "        if length % self.batch_size:\n",
        "            bins += 1                    # 나누어 떨어지지 않을 때\n",
        "        indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞습니다.\n",
        "        x = x[indexes]\n",
        "        y = y[indexes]\n",
        "        for i in range(bins):\n",
        "            start = self.batch_size * i\n",
        "            end = self.batch_size * (i + 1)\n",
        "            yield x[start:end], y[start:end]   # batch_size만큼 슬라이싱하여 반환합니다.\n",
        "\n",
        "    def training(self, x, y):\n",
        "        m = len(x)                # 샘플 개수를 저장합니다.\n",
        "        z = self.forpass(x)       # 정방향 계산을 수행합니다.\n",
        "        a = self.softmax(z)       # 활성화 함수를 적용합니다.\n",
        "        err = a - y           # 오차를 계산합니다.\n",
        "        # 오차를 역전파하여 그래디언트를 계산합니다.\n",
        "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
        "        # 그래디언트에서 페널티 항의 미분 값을 뺍니다\n",
        "        w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\n",
        "        w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m\n",
        "        # 은닉층의 가중치와 절편을 업데이트합니다.\n",
        "        self.w1 -= self.lr * w1_grad\n",
        "        self.b1 -= self.lr * b1_grad\n",
        "        # 출력층의 가중치와 절편을 업데이트합니다.\n",
        "        self.w2 -= self.lr * w2_grad\n",
        "        self.b2 -= self.lr * b2_grad\n",
        "        return a\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = self.forpass(x)          # 정방향 계산을 수행합니다.\n",
        "        return np.argmax(z, axis=1)  # 가장 큰 값의 인덱스를 반환합니다.\n",
        "\n",
        "    def score(self, x, y):\n",
        "        # 예측과 타깃 열 벡터를 비교하여 True의 비율을 반환합니다.\n",
        "        return np.mean(self.predict(x) == np.argmax(y, axis=1))\n",
        "\n",
        "    def reg_loss(self):\n",
        "        # 은닉층과 출력층의 가중치에 규제를 적용합니다.\n",
        "        return self.l1 * (np.sum(np.abs(self.w1)) + np.sum(np.abs(self.w2))) + \\\n",
        "               self.l2 / 2 * (np.sum(self.w1**2) + np.sum(self.w2**2))\n",
        "\n",
        "    def update_val_loss(self, x_val, y_val):\n",
        "        z = self.forpass(x_val)            # 정방향 계산을 수행합니다.\n",
        "        a = self.softmax(z)                # 활성화 함수를 적용합니다.\n",
        "        a = np.clip(a, 1e-10, 1-1e-10)     # 출력 값을 클리핑합니다.\n",
        "        # 크로스 엔트로피 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
        "        val_loss = np.sum(-y_val*np.log(a))\n",
        "        self.val_losses.append((val_loss + self.reg_loss()) / len(y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_-kbQbK11UC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMe-xWpK11UC"
      },
      "outputs": [],
      "source": [
        "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "print(x_train_all.shape, y_train_all.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_all[0][20][20]"
      ],
      "metadata": {
        "id": "_hy1HPadcL7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VayhQ9lp11UC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#print(x_train_all[0])\n",
        "plt.imshow(x_train_all[0], cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7GyJkSE11UC"
      },
      "outputs": [],
      "source": [
        "print(y_train_all[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uS183LJz11UC"
      },
      "outputs": [],
      "source": [
        "class_names = ['티셔츠/윗도리', '바지', '스웨터', '드레스', '코트',\n",
        "               '샌들', '셔츠', '스니커즈', '가방', '앵클부츠']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z37b37Or11UD"
      },
      "outputs": [],
      "source": [
        "print(class_names[y_train_all[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfojHU9y11UD"
      },
      "outputs": [],
      "source": [
        "temp = np.array([1,1,2,2,2,2,3,3,3])\n",
        "np.bincount(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSH-gadz11UD"
      },
      "outputs": [],
      "source": [
        "np.bincount(y_train_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFjgu7ZC11UD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwtLjhGF11UD"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all,\n",
        "                                                  test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c20L8vb11UD"
      },
      "outputs": [],
      "source": [
        "np.bincount(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvXknSav11UD"
      },
      "outputs": [],
      "source": [
        "np.bincount(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os0PbPbY11UD"
      },
      "outputs": [],
      "source": [
        "x_train = x_train / 255\n",
        "x_val = x_val / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eweqq5gE11UD"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(-1, 784)\n",
        "x_val = x_val.reshape(-1, 784)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItXFytgh11UD"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape, x_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1FuRGZy11UD"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "lb.fit_transform([0, 1, 3, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfosfU8L11UD"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.to_categorical([0, 1, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtCZyQjn11UD"
      },
      "outputs": [],
      "source": [
        "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
        "y_val_encoded = tf.keras.utils.to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfLGsEni11UD"
      },
      "outputs": [],
      "source": [
        "print(y_train_encoded.shape, y_val_encoded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqQpNKBS11UD"
      },
      "outputs": [],
      "source": [
        "print(y_train[0], y_train_encoded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP5jNCe011UD"
      },
      "outputs": [],
      "source": [
        "fc = MultiClassNetwork(units=100, batch_size=256)\n",
        "fc.fit(x_train, y_train_encoded,\n",
        "       x_val=x_val, y_val=y_val_encoded, epochs=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRKnTpim11UD"
      },
      "outputs": [],
      "source": [
        "plt.plot(fc.losses)\n",
        "plt.plot(fc.val_losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iteration')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFz0dJNF11UD"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ly4Anq411UE"
      },
      "outputs": [],
      "source": [
        "x = np.array([2, 8, 3, 7, 1, 2, 0, 4, 5])\n",
        "w = np.array([2, 1, 5, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tg4Kjs411UE"
      },
      "outputs": [],
      "source": [
        "# w_r = np.flip(w)\n",
        "w_r = w[::-1]\n",
        "print(w_r)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3,4])\n",
        "print(a[1])"
      ],
      "metadata": {
        "id": "j4jfLlngz8IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2],\n",
        "              [3,4]])  # (2,2)\n",
        "print(a[1])"
      ],
      "metadata": {
        "id": "Dwc6AkCy0QRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dj-JVDF_0_pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3,4])\n",
        "print(a[0:1])"
      ],
      "metadata": {
        "id": "qrbqjLbn0nMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2],\n",
        "              [3,4]])  # (2,2)\n",
        "print(a[1:2])"
      ],
      "metadata": {
        "id": "5DBKrz4-1AWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3,4])  # (4,)\n",
        "print(a[[2,0]])"
      ],
      "metadata": {
        "id": "kX5I4GsU_Fqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3,4,5,6,7,8])  # (8,)\n",
        "idx = np.random.permutation(len(a))\n",
        "idx\n",
        "print(a[idx])"
      ],
      "metadata": {
        "id": "9ONMUNKL_mna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1,1,1,1,1],\n",
        "              [2,2,2,2,2],\n",
        "              [3,3,3,3,3],\n",
        "              [4,4,4,4,4],\n",
        "              [5,5,5,5,5]])   # (5,5)\n",
        "idx = np.random.permutation(len(x))\n",
        "idx\n",
        "print(x[idx])"
      ],
      "metadata": {
        "id": "bEOwoZaDABEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3,4])\n",
        "print(a)    # (4,)\n",
        "print(a.T)  # (4,)\n",
        "print(a.reshape(-1,1))"
      ],
      "metadata": {
        "id": "Wgxx8y1szBv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQ-GY3Y611UE"
      },
      "outputs": [],
      "source": [
        "for i in range(6):\n",
        "    # print(np.sum(x[i:i+4]*w_r))\n",
        "    # print(np.dot(x[i:i+4],w_r))\n",
        "    print(np.dot(x[i:i+4], w_r.reshape(-1,1)))  #(4,)(4,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z2s0RCo11UE"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import convolve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow-tV7po11UE"
      },
      "outputs": [],
      "source": [
        "convolve(x, w, mode='valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXGR0Yf611UE"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import correlate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6ub6khF11UE"
      },
      "outputs": [],
      "source": [
        "correlate(x, w, mode='valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6fqXD5A11UE"
      },
      "outputs": [],
      "source": [
        "correlate(x, w, mode='full')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VP1qcgS11UE"
      },
      "outputs": [],
      "source": [
        "correlate(x, w, mode='same')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkSJ57JK11UE"
      },
      "outputs": [],
      "source": [
        "x = np.array([[1, 2, 3],\n",
        "              [4, 5, 6],\n",
        "              [7, 8, 9]])\n",
        "w = np.array([[2, 0], [0, 0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6NJnsDm11UE"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import correlate2d\n",
        "\n",
        "correlate2d(x, w, mode='valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwF1wGn811UE"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import convolve2d\n",
        "\n",
        "convolve2d(x, w, mode='valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCh9SV8p11UE"
      },
      "outputs": [],
      "source": [
        "correlate2d(x, w, mode='same')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "a = np.array([1,2,3,4])\n",
        "print(type(a))\n",
        "print(a)\n",
        "b = tf.constant(a)\n",
        "print(b.numpy())"
      ],
      "metadata": {
        "id": "KOFKMczg57Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def foo():\n",
        "    print(\"foo()\")\n",
        "    return 10\n",
        "\n",
        "# foo()\n",
        "foo()()"
      ],
      "metadata": {
        "id": "Vrq-l-J76_AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bar():\n",
        "    print(\"bar()\")\n",
        "\n",
        "def wow():\n",
        "    print(\"wow()\")\n",
        "\n",
        "#-----------------------------------------------\n",
        "\n",
        "def foo():\n",
        "    print(\"foo()\")\n",
        "    return bar\n",
        "\n",
        "foo()()"
      ],
      "metadata": {
        "id": "bTGzZ-GSBQUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bar():\n",
        "    print(\"bar()\")\n",
        "\n",
        "def wow():\n",
        "    print(\"wow()\")\n",
        "\n",
        "#-----------------------------------------------\n",
        "\n",
        "def foo(fn):\n",
        "    fn()\n",
        "    print(\"foo()\")\n",
        "\n",
        "\n",
        "foo(wow)"
      ],
      "metadata": {
        "id": "40yHoQUZB0LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class foo:\n",
        "    def __init__(self):\n",
        "        print(\"foo.__init__()\")\n",
        "\n",
        "    def __call__(self):\n",
        "        print(\"foo.__call__()\")\n",
        "\n",
        "foo()()\n"
      ],
      "metadata": {
        "id": "xiBO67n6CF3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Conv2D(filters=1, kernel_size=2, padding='same', kernel_initializer=weight_init)(image)"
      ],
      "metadata": {
        "id": "JXiktnbN65L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p-y7C6m11UE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import *\n",
        "import matplotlib.pyplot as plt\n",
        "image = tf.constant([[[[1],[2],[3]],\n",
        "                      [[4],[5],[6]],\n",
        "                      [[7],[8],[9]]]], dtype=np.float32)\n",
        "print(image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN3_4dU811UE"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image.numpy().reshape(3,3), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMRxMBmb11UE"
      },
      "outputs": [],
      "source": [
        "print(\"image.shpe\", image.shape)\n",
        "weight = np.array([[[[1.]],[[1.]]],[[[1.]],[[1.]]]])\n",
        "print(\"weight.shpe\", weight.shape)\n",
        "weight_init = tf.constant_initializer(weight)\n",
        "conv2d = tf.keras.layers.Conv2D(filters=1, kernel_size=2, padding='valid', kernel_initializer=weight_init)(image)\n",
        "print(\"conv2d.shape\", conv2d.shape)\n",
        "print(conv2d.numpy().reshape(2,2))\n",
        "# plt.imshow(conv2d.numpy().reshape(3,3), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImPhH4UM11UE"
      },
      "outputs": [],
      "source": [
        "print(\"image.shpe\", image.shape)\n",
        "weight = np.array([[[[1.]],[[1.]]],[[[1.]],[[1.]]]])\n",
        "print(\"weight.shpe\", weight.shape)\n",
        "weight_init = tf.constant_initializer(weight)\n",
        "conv2d = tf.keras.layers.Conv2D(filters=1, kernel_size=2, padding='same', kernel_initializer=weight_init)(image)\n",
        "print(\"conv2d.shape\", conv2d.shape)\n",
        "print(conv2d.numpy().reshape(3,3))\n",
        "# plt.imshow(conv2d.numpy().reshape(2,2), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvI5XcAq11UF"
      },
      "outputs": [],
      "source": [
        "conv2d = tf.keras.layers.Conv2D(filters=1, kernel_size=2, padding='same', kernel_initializer=weight_init)(image)\n",
        "print(\"conv2d.shape\", conv2d.shape)\n",
        "print(conv2d.numpy().reshape(3,3))\n",
        "plt.imshow(conv2d.numpy().reshape(3,3), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight = np.array([[[[1.,10.,-1.]],[[1.,10.,-1.]]],[[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
        "# print(weight)\n",
        "a =np.transpose(weight,(3,0,1,2))\n",
        "for data in a:\n",
        "    print(data.reshape(2,2))"
      ],
      "metadata": {
        "id": "EHq1lFMrQhtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft2wBJw-11UF"
      },
      "outputs": [],
      "source": [
        "print(\"image.shpe\", image.shape)\n",
        "weight = np.array([[[[1.,10.,-1.]],[[1.,10.,-1.]]],[[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
        "print(\"weight.shpe\", weight.shape)\n",
        "weight_init = tf.constant_initializer(weight)\n",
        "conv2d = tf.keras.layers.Conv2D(filters=3, kernel_size=2, padding='valid', kernel_initializer=weight_init)(image)\n",
        "print(\"conv2d.shape\", conv2d.shape)\n",
        "print(conv2d)\n",
        "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
        "for i, feature_map in enumerate(feature_maps):\n",
        "    print(feature_map.reshape(2,2))\n",
        "#     plt.subplot(1,3,i+1), plt.imshow(feature_map.reshape(3,3), cmap='gray')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-I0WD6Op11UF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import *\n",
        "import matplotlib.pyplot as plt\n",
        "image = tf.constant([[[[1,1,1],[2,2,2],[3,3,3]],\n",
        "                      [[4,4,4],[5,5,5],[6,6,6]],\n",
        "                      [[7,7,7],[8,8,8],[9,9,9]]]], dtype=np.float32)\n",
        "print(image.shape)\n",
        "weight = np.array([[[[1],[2],[3]],[[1],[2],[3]]],[[[1],[2],[3]],[[1],[2],[3]]]])\n",
        "print(\"weight.shape\", weight.shape)\n",
        "weight_init = tf.constant_initializer(weight)\n",
        "conv2d = tf.keras.layers.Conv2D(filters=1, kernel_size=2, padding='valid', kernel_initializer=weight_init)(image)\n",
        "print(\"conv2d.shape\", conv2d.shape)\n",
        "# print(conv2d)\n",
        "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
        "for i, feature_map in enumerate(feature_maps):\n",
        "    print(feature_map.reshape(2,2))\n",
        "#     plt.subplot(1,3,i+1), plt.imshow(feature_map.reshape(3,3), cmap='gray')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpLdh-vG11UF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import *\n",
        "import matplotlib.pyplot as plt\n",
        "image = tf.constant([[[[1,1,1],[2,2,2],[3,3,3]],\n",
        "                      [[4,4,4],[5,5,5],[6,6,6]],\n",
        "                      [[7,7,7],[8,8,8],[9,9,9]]]], dtype=np.float32)\n",
        "print(image.shape)\n",
        "# weight = np.array([[[[1],[2],[3]],[[1],[2],[3]]],[[[1],[2],[3]],[[1],[2],[3]]]])\n",
        "# print(\"weight.shpe\", weight.shape)\n",
        "# weight_init = tf.constant_initializer(weight)\n",
        "# conv2d = tf.keras.layers.Conv2D(filters=1, kernel_size=2, padding='same', kernel_initializer=weight_init)(image)\n",
        "# print(\"conv2d.shape\", conv2d.shape)\n",
        "# print(conv2d)\n",
        "# feature_maps = np.swapaxes(conv2d, 0, 3)\n",
        "# for i, feature_map in enumerate(feature_maps):\n",
        "#     print(feature_map.reshape(3,3))\n",
        "#     plt.subplot(1,3,i+1), plt.imshow(feature_map.reshape(3,3), cmap='gray')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJeovJxi11UF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "a = np.arange(15).reshape(3,5)\n",
        "print(np.swapaxes(a, 0, 1))\n",
        "print(a.T)\n",
        "np.transpose(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqZPP_vC11UF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "a = np.arange(24).reshape(2,3,4)\n",
        "print(a)\n",
        "print(a.T)\n",
        "np.swapaxes(a,0,2)\n",
        "np.swapaxes(a,0,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPo4OAnl11UF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "conv2d = np.array([[[[1,2],[3,4]],[[5,6],[7,8]]],[[[9,10],[11,12]],[[13,14],[15,16]]]])\n",
        "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
        "print(feature_maps)\n",
        "\n",
        "for i, feature in enumerate(feature_maps):\n",
        "    print(i, feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw19Avsa11UF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import *\n",
        "import matplotlib.pyplot as plt\n",
        "image = tf.constant([[[[1,1,1],[2,2,2],[3,3,3]],\n",
        "                      [[4,4,4],[5,5,5],[6,6,6]],\n",
        "                      [[7,7,7],[8,8,8],[9,9,9]]]], dtype=np.float32)\n",
        "print(image.shape)\n",
        "weight = np.array([[[[1,1],[2,2],[3,3]],[[1,1],[2,2],[3,3]]],[[[1,1],[2,2],[3,3]],[[1,1],[2,2],[3,3]]]])\n",
        "print(\"weight.shpe\", weight.shape)\n",
        "weight_init = tf.constant_initializer(weight)\n",
        "conv2d = tf.keras.layers.Conv2D(filters=2, kernel_size=2, padding='valid', kernel_initializer=weight_init)(image)\n",
        "print(\"conv2d.shape\", conv2d.shape)\n",
        "# print(conv2d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d28RAngO11UF"
      },
      "outputs": [],
      "source": [
        "image = tf.constant([[[[4],[3]],[[2],[1]]]], dtype=np.float32)\n",
        "pool = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=1, padding='valid')(image)\n",
        "print(image.shape)\n",
        "print(pool.shape)\n",
        "# print(pool.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGlvLaeG11UF"
      },
      "outputs": [],
      "source": [
        "image = tf.constant([[[[1],[2]],[[3],[4]]]], dtype=np.float32)\n",
        "pool = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=1, padding='same')(image)\n",
        "print(pool.shape)\n",
        "print(pool.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOI6_EPp11UF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import *\n",
        "import matplotlib.pyplot as plt\n",
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0','1','2','3','4','5','6','7','8','9']\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "\n",
        "img = train_images[0]\n",
        "print(type(img))\n",
        "print(img.shape)\n",
        "plt.imshow( img, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fm6W9Im11UF"
      },
      "outputs": [],
      "source": [
        "img = img.reshape(-1,28,28,1)\n",
        "# print(img.shape)\n",
        "img_tf = tf.convert_to_tensor(img)\n",
        "# print(img_tf.shape)\n",
        "# print(img_tf)\n",
        "weight_init = keras.initializers.RandomNormal(stddev=0.01)\n",
        "# # print(weight_init)\n",
        "conv2d = tf.keras.layers.Conv2D(5, kernel_size=3, padding='valid',\n",
        "                             strides=(1,1), kernel_initializer=weight_init)(img_tf)\n",
        "print(\"conv2d.shape\", conv2d.shape)  # (1,26,26,5)\n",
        "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
        "for i, feature_map in enumerate(feature_maps):\n",
        "    plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(26,26), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laYIlv0-11UF"
      },
      "outputs": [],
      "source": [
        "pool = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same')(conv2d)\n",
        "print(pool.shape)\n",
        "feature_maps = np.swapaxes(pool, 0, 3)\n",
        "for i, feature_map in enumerate(feature_maps):\n",
        "    plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(13,13), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYB-GOqT11UF"
      },
      "outputs": [],
      "source": [
        "zs = np.arange(-10., 10., 0.1)\n",
        "gs = [1/(1+np.exp(-z)) for z in zs]\n",
        "plt.plot(zs, gs)\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('1/(1+e^-z)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xd9Vb1Z11UF"
      },
      "outputs": [],
      "source": [
        "def  sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "zs = np.arange(-10., 10., 0.1)\n",
        "gs = [ sigmoid(z)*(1-sigmoid(z)) for z in zs]\n",
        "plt.plot(zs, gs)\n",
        "plt.ylim(0,1)\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('sigmoid() derivative')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcslH5Xg11UF"
      },
      "outputs": [],
      "source": [
        "zs = np.arange(-10., 10., 0.1)\n",
        "gs = [ np.tanh(z) for z in zs]\n",
        "plt.plot(zs, gs)\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('tanh()')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhUx5qYM11UF"
      },
      "outputs": [],
      "source": [
        "def  sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "zs = np.arange(-10., 10., 0.1)\n",
        "gs = [ (1-np.tanh(z))*(1+np.tanh(z)) for z in zs]\n",
        "plt.plot(zs, gs)\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('tanh() deivative')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB1LQam311UG"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    return np.maximum(x, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92CD72bY11UG"
      },
      "outputs": [],
      "source": [
        "x = np.array([-1, 2, -3, 4, -5])\n",
        "relu(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsEAdgcT11UG"
      },
      "outputs": [],
      "source": [
        "zs = np.arange(-10., 10., 0.1)\n",
        "gs = [ relu(z) for z in zs]\n",
        "plt.plot(zs, gs)\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('relu()')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYPR17fi11UG"
      },
      "outputs": [],
      "source": [
        "r_out = tf.nn.relu(x)\n",
        "r_out.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ab9AO0i11UG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class ConvolutionNetwork:\n",
        "\n",
        "    def __init__(self, n_kernels=10, units=10, batch_size=32, learning_rate=0.1):\n",
        "        self.n_kernels = n_kernels  # 합성곱의 커널 개수\n",
        "        self.kernel_size = 3        # 커널 크기\n",
        "        self.optimizer = None       # 옵티마이저\n",
        "        self.conv_w = None          # 합성곱 층의 가중치\n",
        "        self.conv_b = None          # 합성곱 층의 절편\n",
        "        self.units = units          # 은닉층의 뉴런 개수\n",
        "        self.batch_size = batch_size  # 배치 크기\n",
        "        self.w1 = None              # 은닉층의 가중치\n",
        "        self.b1 = None              # 은닉층의 절편\n",
        "        self.w2 = None              # 출력층의 가중치\n",
        "        self.b2 = None              # 출력층의 절편\n",
        "        self.a1 = None              # 은닉층의 활성화 출력\n",
        "        self.losses = []            # 훈련 손실\n",
        "        self.val_losses = []        # 검증 손실\n",
        "        self.lr = learning_rate     # 학습률\n",
        "\n",
        "    def forpass(self, x):\n",
        "        # 3x3 합성곱 연산을 수행합니다.\n",
        "#         print('x.shape',x.shape)\n",
        "#         print('self.conv_w.shape',self.conv_w.shape)\n",
        "#         print('self.conv_w',self.conv_w)\n",
        "        c_out = tf.nn.conv2d(x, self.conv_w, strides=1, padding='SAME') + self.conv_b\n",
        "        # 렐루 활성화 함수를 적용합니다.\n",
        "#         print('c_out.shape',c_out.shape)\n",
        "#         print('c_out',c_out)\n",
        "        r_out = tf.nn.relu(c_out)\n",
        "#         print('r_out.shape',r_out.shape)\n",
        "#         print('r_out',r_out)\n",
        "        # 2x2 최대 풀링을 적용합니다.\n",
        "        p_out = tf.nn.max_pool2d(r_out, ksize=2, strides=2, padding='VALID')\n",
        "        # 첫 번째 배치 차원을 제외하고 출력을 일렬로 펼칩니다.\n",
        "#         print('p_out.shape',p_out.shape)\n",
        "#         print('p_out',p_out)\n",
        "        f_out = tf.reshape(p_out, [x.shape[0], -1])\n",
        "#         print('f_out.shape',f_out.shape)\n",
        "        z1 = tf.matmul(f_out, self.w1) + self.b1     # 첫 번째 층의 선형 식을 계산합니다\n",
        "        a1 = tf.nn.relu(z1)                          # 활성화 함수를 적용합니다\n",
        "        z2 = tf.matmul(a1, self.w2) + self.b2        # 두 번째 층의 선형 식을 계산합니다.\n",
        "        return z2\n",
        "\n",
        "    def init_weights(self, input_shape, n_classes):\n",
        "        g = tf.initializers.glorot_uniform()\n",
        "        self.conv_w = tf.Variable(g((3, 3, 1, self.n_kernels)))\n",
        "        self.conv_b = tf.Variable(np.zeros(self.n_kernels), dtype=float)\n",
        "        n_features = 14 * 14 * self.n_kernels\n",
        "        self.w1 = tf.Variable(g((n_features, self.units)))          # (특성 개수, 은닉층의 크기)\n",
        "        self.b1 = tf.Variable(np.zeros(self.units), dtype=float)    # 은닉층의 크기\n",
        "        self.w2 = tf.Variable(g((self.units, n_classes)))           # (은닉층의 크기, 클래스 개수)\n",
        "        self.b2 = tf.Variable(np.zeros(n_classes), dtype=float)     # 클래스 개수\n",
        "\n",
        "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
        "        self.init_weights(x.shape, y.shape[1])    # 은닉층과 출력층의 가중치를 초기화합니다.\n",
        "        self.optimizer = tf.optimizers.SGD(learning_rate=self.lr)\n",
        "        # epochs만큼 반복합니다.\n",
        "        for i in range(epochs):\n",
        "            print('에포크', i, end=' ')\n",
        "            # 제너레이터 함수에서 반환한 미니배치를 순환합니다.\n",
        "            batch_losses = []\n",
        "            for x_batch, y_batch in self.gen_batch(x, y):\n",
        "                print('.', end='')\n",
        "                self.training(x_batch, y_batch)\n",
        "                # 배치 손실을 기록합니다.\n",
        "                batch_losses.append(self.get_loss(x_batch, y_batch))\n",
        "\n",
        "            print()\n",
        "            # 배치 손실 평균내어 훈련 손실 값으로 저장합니다.\n",
        "            self.losses.append(np.mean(batch_losses))\n",
        "            # 검증 세트에 대한 손실을 계산합니다.\n",
        "            self.val_losses.append(self.get_loss(x_val, y_val))\n",
        "\n",
        "    # 미니배치 제너레이터 함수\n",
        "    def gen_batch(self, x, y):\n",
        "        bins = len(x) // self.batch_size                   # 미니배치 횟수\n",
        "        indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞습니다.\n",
        "        x = x[indexes]\n",
        "        y = y[indexes]\n",
        "        for i in range(bins):\n",
        "            start = self.batch_size * i\n",
        "            end = self.batch_size * (i + 1)\n",
        "            yield x[start:end], y[start:end]   # batch_size만큼 슬라이싱하여 반환합니다.\n",
        "\n",
        "    def training(self, x, y):\n",
        "        m = len(x)                    # 샘플 개수를 저장합니다.\n",
        "        with tf.GradientTape() as tape:\n",
        "            z = self.forpass(x)       # 정방향 계산을 수행합니다.\n",
        "            # 손실을 계산합니다.\n",
        "            loss = tf.nn.softmax_cross_entropy_with_logits(y, z)\n",
        "            loss = tf.reduce_mean(loss)\n",
        "\n",
        "        weights_list = [self.conv_w, self.conv_b,\n",
        "                        self.w1, self.b1, self.w2, self.b2]\n",
        "        # 가중치에 대한 그래디언트를 계산합니다.\n",
        "        grads = tape.gradient(loss, weights_list)\n",
        "        # 가중치를 업데이트합니다.\n",
        "        self.optimizer.apply_gradients(zip(grads, weights_list))\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = self.forpass(x)                 # 정방향 계산을 수행합니다.\n",
        "        return np.argmax(z.numpy(), axis=1) # 가장 큰 값의 인덱스를 반환합니다.\n",
        "\n",
        "    def score(self, x, y):\n",
        "        # 예측과 타깃 열 벡터를 비교하여 True의 비율을 반환합니다.\n",
        "        return np.mean(self.predict(x) == np.argmax(y, axis=1))\n",
        "\n",
        "    def get_loss(self, x, y):\n",
        "        z = self.forpass(x)                 # 정방향 계산을 수행합니다.\n",
        "        # 손실을 계산하여 저장합니다.\n",
        "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, z))\n",
        "        return loss.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK9Y6hXB11UG"
      },
      "outputs": [],
      "source": [
        "x = tf.Variable(np.array([1.0, 2.0, 3.0]))\n",
        "with tf.GradientTape() as tape:\n",
        "    y = x ** 3 + 2 * x + 5  # 3 x ** 2 + 2\n",
        "\n",
        "print(y)\n",
        "# 그래디언트를 계산합니댜.\n",
        "print(tape.gradient(y, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPWE0PBD11UG"
      },
      "outputs": [],
      "source": [
        "x = tf.Variable(np.array([1.0, 2.0, 3.0]))\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.nn.softmax(x)\n",
        "\n",
        "print(y)\n",
        "# 그래디언트를 계산합니다.\n",
        "print(tape.gradient(y, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPFxtawt11UG"
      },
      "outputs": [],
      "source": [
        "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xjgdodC11UG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all,\n",
        "                                                  test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhxF-tLb11UG"
      },
      "outputs": [],
      "source": [
        "print(y_train[0])\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_DsDwFS11UG"
      },
      "outputs": [],
      "source": [
        "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
        "y_val_encoded = tf.keras.utils.to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OJFlso_11UG"
      },
      "outputs": [],
      "source": [
        "print(y_train_encoded[0])\n",
        "print(y_train_encoded.shape)\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do7je89x11UG"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_val = x_val.reshape(-1, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJVGKNIj11UG"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)\n",
        "print(x_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1vw7V0W11UG"
      },
      "outputs": [],
      "source": [
        "x_train = x_train / 255\n",
        "x_val = x_val / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Rxz8xvJ11UG"
      },
      "outputs": [],
      "source": [
        "cn = ConvolutionNetwork(n_kernels=10, units=100, batch_size=128, learning_rate=0.01)\n",
        "cn.fit(x_train, y_train_encoded,\n",
        "       x_val=x_val, y_val=y_val_encoded, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "518z8jxy11UG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B44DA6OX11UG"
      },
      "outputs": [],
      "source": [
        "plt.plot(cn.losses)\n",
        "plt.plot(cn.val_losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iteration')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s-iXMPw11UG"
      },
      "outputs": [],
      "source": [
        "cn.score(x_val, y_val_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK5kEy3F11UH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}