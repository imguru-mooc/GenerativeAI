{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##ğŸ¤ ìŒì„± ì¸ì‹ + í•©ì„± ì˜ˆì œ: Whisper + TTS\n",
        "\n",
        "ğŸ§° ì‚¬ìš© ë„êµ¬\n",
        "\n",
        "| ê¸°ëŠ¥    | ë„êµ¬                                                    | ì„¤ëª…               |\n",
        "| ----- | ----------------------------------------------------- | ---------------- |\n",
        "| ìŒì„± ì¸ì‹ | [`openai/whisper`](https://github.com/openai/whisper) | ê³ ì„±ëŠ¥ ë‹¤êµ­ì–´ ìŒì„± ì¸ì‹ ëª¨ë¸ |\n",
        "| ìŒì„± í•©ì„± | `TTS` (Coqui.ai or pyttsx3 / gTTS)                    | í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜     |\n",
        "\n"
      ],
      "metadata": {
        "id": "btNHnE81gTIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###âœ… 1. Whisper ì„¤ì¹˜ ë° ì¸ì‹\n",
        "\n",
        "ğŸ”§ ì„¤ì¹˜"
      ],
      "metadata": {
        "id": "HQ9lk8Qpgfmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "3yROl5uyghnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ§ ìƒ˜í”Œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ (ì˜ì–´)"
      ],
      "metadata": {
        "id": "5i1FaugzgwFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/gloveboxes/OpenAI-Whisper-Transcriber-Sample/raw/master/harvard.wav -O harvard.wav\n"
      ],
      "metadata": {
        "id": "bqCKEvNRgnxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ§  ì¸ì‹ ì½”ë“œ"
      ],
      "metadata": {
        "id": "-AtsomhXg1xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# ëª¨ë¸ ë¡œë”©\n",
        "model = whisper.load_model(\"base\")  # base, small, medium, large\n",
        "\n",
        "# ìŒì„± íŒŒì¼ ì²˜ë¦¬\n",
        "result = model.transcribe(\"harvard.wav\")\n",
        "print(\"ğŸ§ ì¸ì‹ëœ í…ìŠ¤íŠ¸:\\n\", result[\"text\"])"
      ],
      "metadata": {
        "id": "f1-9EJrUgze5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”Š ìŒì„± í•©ì„± (Text-to-Speech) ì˜ˆì œ\n",
        "\n",
        "ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ë ¤ë©´ gTTS ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
      ],
      "metadata": {
        "id": "SXkhhF8ghkMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS"
      ],
      "metadata": {
        "id": "n8xMINh_hs-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "\n",
        "# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜\n",
        "tts = gTTS(text=result[\"text\"], lang='en')\n",
        "tts.save(\"output.mp3\")\n",
        "\n",
        "# ì˜¤ë””ì˜¤ ì¬ìƒ\n",
        "Audio(\"output.mp3\")"
      ],
      "metadata": {
        "id": "Bj8LsGPqg8u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ğŸ§ í•œêµ­ì–´ Whisper + TTS ìŒì„± ì‹¤ìŠµ ì˜ˆì œ"
      ],
      "metadata": {
        "id": "7nv6hdiTjNK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… 1. í•œêµ­ì–´ ìŒì„± íŒŒì¼ ì¤€ë¹„ (ì˜ˆ: ìŒì„± ìƒ˜í”Œ ì—…ë¡œë“œ ë˜ëŠ” ë‹¤ìš´ë¡œë“œ)\n",
        "\n",
        "[KSS Dataset](https://www.kaggle.com/datasets/bryanpark/korean-single-speaker-speech-dataset) (Korean)ì—ì„œ  ë‹¤ìš´ë¡œë“œ"
      ],
      "metadata": {
        "id": "7tXFnPT4jQvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"bryanpark/korean-single-speaker-speech-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "C59q9wzGhn7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "wav_path = \"/root/.cache/kagglehub/datasets/bryanpark/korean-single-speaker-speech-dataset/versions/4/kss/1/1_0000.wav\"\n",
        "\n",
        "# ì˜¤ë””ì˜¤ ì¬ìƒ\n",
        "Audio(wav_path)"
      ],
      "metadata": {
        "id": "2gMqZiAQkJSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… 3. Whisperë¡œ í•œêµ­ì–´ ìŒì„± ì¸ì‹"
      ],
      "metadata": {
        "id": "Rr5Zv2TSk1pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")  # small/medium/large ê°€ëŠ¥\n",
        "result = model.transcribe(wav_path)\n",
        "print(\"ğŸ“ ì¸ì‹ ê²°ê³¼:\", result[\"text\"])\n"
      ],
      "metadata": {
        "id": "qFvO6ttUktkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… 4. TTSë¡œ í•œêµ­ì–´ ìŒì„± ìƒì„±\n",
        "\n",
        "â–¶ï¸ gTTS (ê°„ë‹¨í•˜ê³  ë¹ ë¦„)"
      ],
      "metadata": {
        "id": "7VnO-6XJlKvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "\n",
        "text = result[\"text\"]\n",
        "tts = gTTS(text=text, lang='ko')\n",
        "tts.save(\"korean_tts.mp3\")\n",
        "Audio(\"korean_tts.mp3\")\n"
      ],
      "metadata": {
        "id": "840DwHu-lFJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ğŸ“ Colab ê¸°ë°˜ AI ìŒì„± ë¹„ì„œ ì‹œìŠ¤í…œ (í•œêµ­ì–´)\n",
        "\n",
        "| ë‹¨ê³„       | ë„êµ¬               | ì„¤ëª…              |\n",
        "| -------- | ---------------- | --------------- |\n",
        "| ğŸ™ ì…ë ¥    | ë§ˆì´í¬ ë˜ëŠ” WAV íŒŒì¼    | ì‚¬ìš©ìì˜ ì§ˆë¬¸ ìˆ˜ì§‘      |\n",
        "| ğŸ“ ìŒì„± ì¸ì‹ | Whisper          | ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜     |\n",
        "| ğŸ’¬ ì‘ë‹µ ìƒì„± | OpenAI / Rule ê¸°ë°˜ | ê°„ë‹¨í•œ ì±—ë´‡ ë˜ëŠ” LLM   |\n",
        "| ğŸ”Š ìŒì„± í•©ì„± | gTTS / Coqui TTS | í•œêµ­ì–´ í…ìŠ¤íŠ¸ â†’ ìŒì„± ì¶œë ¥ |\n"
      ],
      "metadata": {
        "id": "88C3opzzl_LN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
      ],
      "metadata": {
        "id": "UTjxgwB0mFjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install gTTS\n",
        "!pip install pydub"
      ],
      "metadata": {
        "id": "vCX0INqwlgSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… 2. ì‚¬ì „ ì¤€ë¹„ â€“ Colabì— í•œêµ­ì–´ ìŒì„± íŒŒì¼ ì—…ë¡œë“œ"
      ],
      "metadata": {
        "id": "4mNwf4t1mPW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ¤ Windows ë…¹ìŒê¸°ì—ì„œ ë…¹ìŒí•œ ìŒì„± ì €ì¥ ë°©ë²•\n",
        "\n",
        "âœ… 1. Windows ë…¹ìŒê¸° ì—´ê¸°\n",
        "\n",
        "- ê²€ìƒ‰ì°½ì— \"ë…¹ìŒê¸°\" ë˜ëŠ” \"Voice Recorder\" ì…ë ¥ í›„ ì•± ì‹¤í–‰\n",
        "\n",
        "- ë˜ëŠ” ìœˆë„ìš° í‚¤ + R â†’ soundrecorder ë˜ëŠ” VoiceRecorder ì…ë ¥ í›„ ì‹¤í–‰\n",
        "\n",
        "âœ… 2. ë…¹ìŒ ì‹œì‘ ë° ì €ì¥\n",
        "\n",
        "1. â— ë²„íŠ¼ í´ë¦­í•˜ì—¬ ë…¹ìŒ ì‹œì‘\n",
        "\n",
        "2. â–  ë²„íŠ¼ í´ë¦­í•˜ì—¬ ë…¹ìŒ ì¢…ë£Œ\n",
        "\n",
        "3. ì¢Œì¸¡ ëª©ë¡ì— ë…¹ìŒ íŒŒì¼ì´ ìë™ ì €ì¥ë¨\n",
        "\n",
        "4. ë…¹ìŒê¸° ì•±ì—ì„œ ìš°í´ë¦­ â†’ íŒŒì¼ ìœ„ì¹˜ ì—´ê¸°ë¡œ ì´ë™ ê°€ëŠ¥\n",
        "\n",
        "âœ… 4. íŒŒì¼ í˜•ì‹\n",
        "\n",
        "- ê¸°ë³¸ ì €ì¥ í˜•ì‹ì€ .m4a (AAC ì••ì¶•)\n",
        "\n",
        "- Whisperì—ì„œëŠ” .wav ê¶Œì¥ â†’ ë³€í™˜ í•„ìš” ì‹œ Audacity ë˜ëŠ” ffmpeg ì‚¬ìš©"
      ],
      "metadata": {
        "id": "PJhHsQsHrj_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"ğŸ”¼ ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”\")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "VWQqnu-7mX1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ” m4a â†’ wav ë³€í™˜ (Whisperìš©)\n",
        "\n",
        "â–¶ï¸ Python ì½”ë“œë¡œ ë³€í™˜"
      ],
      "metadata": {
        "id": "Bp7oso5psJuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# m4a íŒŒì¼ì„ wavë¡œ ë³€í™˜\n",
        "m4a = AudioSegment.from_file(\"ë…¹ìŒ.m4a\", format=\"m4a\")\n",
        "m4a.export(\"converted.wav\", format=\"wav\")"
      ],
      "metadata": {
        "id": "lxlvuqivsLhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… Whisperë¡œ í•œêµ­ì–´ ìŒì„± ì¸ì‹"
      ],
      "metadata": {
        "id": "0V4LgVN0sxWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"converted.wav\", language=\"ko\")\n",
        "recognized_text = result[\"text\"]\n",
        "print(\"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:\", recognized_text)\n"
      ],
      "metadata": {
        "id": "MILTKI0_szWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ ìƒì„±"
      ],
      "metadata": {
        "id": "ohcqL-h7s9EK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def respond_to(text):\n",
        "    if \"ë‚ ì”¨\" in text:\n",
        "        return \"ì˜¤ëŠ˜ì€ ë§‘ê³  ê¸°ì˜¨ì€ 22ë„ì…ë‹ˆë‹¤.\"\n",
        "    elif \"ì‹œ\" in text:\n",
        "        from datetime import datetime\n",
        "        return f\"ì§€ê¸ˆì€ {datetime.now().strftime('%Hì‹œ %Më¶„ì…ë‹ˆë‹¤')}.\"\n",
        "    elif \"ì•ˆë…•\" in text:\n",
        "        return \"ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"\n",
        "    else:\n",
        "        return \"ì£„ì†¡í•´ìš”. ì•„ì§ ê·¸ ìš”ì²­ì€ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”.\"\n",
        "\n",
        "response_text = respond_to(recognized_text)\n",
        "print(\"ğŸ¤– ì‘ë‹µ:\", response_text)\n"
      ],
      "metadata": {
        "id": "N1l4anT7mMXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… TTS ìŒì„±ìœ¼ë¡œ ì‘ë‹µ ìƒì„± ë° ì¬ìƒ"
      ],
      "metadata": {
        "id": "6BNDd0pNtMiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "\n",
        "tts = gTTS(text=response_text, lang='ko')\n",
        "tts.save(\"response.mp3\")\n",
        "Audio(\"response.mp3\")"
      ],
      "metadata": {
        "id": "9OVNIw2XmUeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ğŸ§  LLaMA3 + Whisper + gTTS ê¸°ë°˜ AI ìŒì„± ë¹„ì„œ (Colabìš©)"
      ],
      "metadata": {
        "id": "BDaWfCQqtrod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… Hugging Face ë¡œê·¸ì¸ (LLaMA3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œìš©)"
      ],
      "metadata": {
        "id": "uyRjjsSgtw5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate pandas"
      ],
      "metadata": {
        "id": "pBB3DU0Tw8ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# ğŸ”‘ ì—¬ê¸°ì—ì„œ Hugging Face Access Token ì…ë ¥ (https://huggingface.co/settings/tokens)\n",
        "login(\"hf_your_access_token_here\")\n"
      ],
      "metadata": {
        "id": "JlqraQ38tRby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… ìŒì„± íŒŒì¼ ì—…ë¡œë“œ (ë§ˆì´í¬ ì…ë ¥ ëŒ€ì‹ )"
      ],
      "metadata": {
        "id": "dMyPdZYYuRyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"ğŸ¤ ì§ˆë¬¸ ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì˜ˆ: korean_question.wav)\")\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "id": "bm3NTPEpuTHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ” m4a â†’ wav ë³€í™˜ (Whisperìš©)"
      ],
      "metadata": {
        "id": "enL3W3Egu4Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# m4a íŒŒì¼ì„ wavë¡œ ë³€í™˜\n",
        "m4a = AudioSegment.from_file(\"ë…¹ìŒ.m4a\", format=\"m4a\")\n",
        "m4a.export(\"converted.wav\", format=\"wav\")"
      ],
      "metadata": {
        "id": "ATyKBnXouwQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… Whisperë¡œ í•œêµ­ì–´ ìŒì„± ì¸ì‹"
      ],
      "metadata": {
        "id": "t36E9KFUvB2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"converted.wav\", language=\"ko\")\n",
        "recognized_text = result[\"text\"]\n",
        "print(\"ğŸ“ ì¸ì‹ëœ ì§ˆë¬¸:\", recognized_text)"
      ],
      "metadata": {
        "id": "TsopLcFQu750"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… 5. LLaMA3 ê¸°ë°˜ ìì—°ì–´ ì‘ë‹µ ìƒì„±"
      ],
      "metadata": {
        "id": "d1tj7IsdviM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ìµœì´ˆ ì‹¤í–‰ ì‹œ ì‹œê°„ ì†Œìš”)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
        "prompt = f\"\"\"\n",
        "ë‹¹ì‹ ì€ ì¹œì ˆí•œ í•œêµ­ì–´ AI ë¹„ì„œì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •ì¤‘í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
        "\n",
        "ì§ˆë¬¸: {recognized_text}\n",
        "ë‹µë³€:\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)\n",
        "response_text = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"ë‹µë³€:\")[-1].strip()\n",
        "\n",
        "print(\"ğŸ¤– LLaMA3 ì‘ë‹µ:\", response_text)\n"
      ],
      "metadata": {
        "id": "kIwgoGIzvGv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… gTTSë¡œ ìŒì„± ì‘ë‹µ ìƒì„±"
      ],
      "metadata": {
        "id": "oWTjqkwNyf0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "\n",
        "tts = gTTS(text=response_text, lang='ko')\n",
        "tts.save(\"response.mp3\")\n",
        "Audio(\"response.mp3\")"
      ],
      "metadata": {
        "id": "DltmXV1ovjzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jL853kx6yrOY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}